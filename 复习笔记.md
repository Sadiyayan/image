

## 1. 中间件：

![Cgq2xl6ECbaAEf3bAAOZBy1Q3a0488.png](https://s0.lgstatic.com/i/image3/M01/0E/7A/Ciqah16T5Z2AWqplAAOZBy1Q3a0272.png)

### 1.1 zookeeper

```java
1.zookeeper是如何保证cp的？
  eureka如何保证ap？
  
2.分布式锁的理解：
假设有一万个请求同一个服务，这个服务经过负载均衡分布到不同ip的主机上，逻辑上是对同一个数据的数据进行修改和查询，在这部分逻辑上，加上如redis、zookeeper这样的分布式锁，可以实现分布式下高并发修改数据的正确性。

3.zookeeper分布式锁：每个请求过来在zookeeper的/lock节点下依次创建临时顺序结点，其中序号最小的节点才能得到锁，每个节点监听比他小的最大序号节点（依照zookeeper的监听机制），实现分布式锁。

4.zookeeper功能：分布式服务管理框架
1）统一命名
2）统一配置（监听节点） 监听节点数据变化//所有客户端监听zookeeper下的节点，节点变化通知客户端
3）注册中心（监听节点） 监听节点个数变化
4）软负载均衡
```



### 1.2 redis

```java
// 将redis内存中的序列化的集合名称用String重新命名（增加可读性）
        // 就是在redis的客户端读取key时可以看明白
        RedisSerializer rs = new StringRedisSerializer();
        redisTemplate.setKeySerializer(rs);

// 对应措施？
缓存穿透：缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。
缓存击穿：缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力
缓存雪崩：缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。


1.五种数据类型
	string
	list(类似双端队列，或者说双向链表)
	set
	hash
	zset(根据score排序value)

2.持久化方式
	rdb:
		自动备份:
			1) shutdown后自动备份入dump.rdb
			2) 每过多久变更多少次数据会写入dump.rdb
		手动备份:
			直接 save
	aof:
		所有写命令会放入到一个文件中，开机自动读取，通常设置为每过一秒更新一次数据

3.事务性质
	隔离性：所有命令都会按照顺序执行，事务在执行的过程中，不会被其他客户端送来的命令打断。
	
	无隔离级别：队列中的命令没有提交之前都不会被实际的执行，不存在“事务中查询要看到
	事务里的更新，事务外查询不能看到”这个头疼的问题。
	
	无原子性：冤有头债有主，如果一个命令失败，但是别的命令可能会执行成功，没有回滚。
	
4.Sentinel实现Redis的高可用
	每一台服务器中创建一个配置文件sentinel.conf，并启动，该哨兵会监控主服务器状态，一旦下线，会在slave中重新选取master作为主，不会导致因为master下线不可用而不能写数据.当原来的master重新回来之后，刚开始自立门户是master，过一小段时间，哨兵检查并将其加入到slave群中。

5.redis实现分布式锁
	redis是单线程的，命令具有原子性，是实现分布式锁的基础。
	考虑两点：1) setnx  2)设置过期时间，剩余时间小于三分之一的时候，增加过期时间
	
6.(具体底层还没有细看，需要仔细看一下，并比较一下和zookeeper的区别，为什么一个高可靠一个高性能！)
	
```

### 1.3 RabbitMQ

```java
1.MQ处理的问题
	异步处理：消息队列的终端可以同时执行多个任务，异步进行
	应用解耦：两个应用程序通过MQ逻辑连接
	流量削峰：应用秒杀（MQ可以处理大量请求）防止请求过多导致应用服务挂掉，rabbitmq采用Qos功能，设置prefetch			  的值，保证应用可以消费的消息数量，实现流量削峰；也可以在mq中设置队列的最大值，实现流量削峰
2.背景知识
	AMQP //数据传输中的协议
	JMS //Java操纵MQ的一套接口
3.rabbitMQ 高可靠 (erlang开发)，响应快-微秒级别，单机吞吐量-万级
    rabbitMQ保证高可靠即消息不丢失从三个角度考虑:
         1) 服务器消息不丢失，即路由、队列、消息都需要持久化
         2) 消费方不丢失消息，分为自动确认和手动确认，只有消费方发送ACK后，服务器队列中的消息才可以删除
         3) 生产者确保消息正确投递，主要用到confirm模式，发送后回调实现了ConfirmCallback的自定义
             的类，进行逻辑判断成功与否
  Kafka 高性能

4.rabbitmq组件
    Broker：服务器实体，可以包含多个虚拟主机！
    Virtual Host：虚拟主机，包含Queue,Exchange,和Binding机制
    	Exchange：交换机（路由），接受消息并发送给队列
    	Queue：存放消息
    	Binding：将队列和交换机绑定
    Channel：双向数据流通道，复用tcp连接，发布消息、订阅队列、接收消息都是通过channel完成的
    Connection:一个Connection中含有多个channel
        
    Publisher：生产者
    Consumer：消费者
5.工作模式
    点对点（P2P）：生产者->消息队列->消费者
        // 一个消息只能存入一个队列并只被一个消费者消费
    	流程：根据连接创建channel，由channel创建mqQueue，然后生产消费
    	模式：
    		简单模式 ：一个生产者，一个队列，一个消费者
    		工作队列模式：一个生产者，一个队列，多个消费者（多个消费者可以用线程池来代替）
        		这个模式的目的是避免简单模式下的消息被积压
    发布订阅：生产者-> 路由(依照路由属性给消息队列) -> 消息队列 -> 消费者
        // 一条（带有路由键）消息根据路由属性可以放入多个binding的队列，可能被多个消费者消费
        依照路由属性区分工作模式：
        	fanout（扇出）：消费会派给binding所有路由的队列
        	direct（定向）：依照消息的路由键和binding路由队列的路由键进行匹配
        	topic（主题）：和direct 90%一样，只是路由键支持了模糊匹配
  6. 消费端限流
      目的：当队列的消息积压过多时，防止消费端一下子获取太多消息，导致宕机，所以要限流
      原理：RabbitMQ 提供了Qos的功能，设置属性prefetch的值，表示该消费者最多会从队列中拿到的消息数量，只要消费者消息数量小于设置的值，队列就会向该消费者发送消息，标志是服务器收到该消息的ACK（通过消费者发回消息的id来告诉服务器这条消息已经被消费者成功接收了）
  7.死信
        DLX（Dead Letter Exchanges）死信交换机/死信邮箱，当消息在队列中由于某些原因没有被及时消费而变成死信(dead message)后，这些消息就会被分发到DLX交换机中，而绑定DLX交换机的队列，称之为：“死信队列”
        原因：
             消息被拒绝，并且不再重新投递 requeue=false
		    消息超时未消费
		    达到最大队列长度
```

### 1.4Kafka

```java
1.Kafka是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统）
	// 1.kafka为什么要用zookeeper？	
    ZooKeeper 作为给分布式系统提供协调服务的工具被 kafka 所依赖。在分布式系统中，消费者需要知道有哪些生产者可用的，而如果每次消费者都需要和生产者建立连接并测试是否成功连接，那效率也太低了，显然是不可取的。而通过使用 ZooKeeper 协调服务，Kafka 就能将 Producer，Consumer，Broker 等结合在一起，同时借助 ZooKeeper,Kafka 就能够将所有组件在无状态的条件下建立起生产者和消费者的订阅关系，实现负载均衡
    // 2.kafka为什么吞吐量大
    rabbitmq集群的所有消息都会落到leader节点上，也就是说所有消息请求都只会在一台服务器上执行，而kafka是partition机制，请求的消息按照生产者消息分发落到不同机器的partition上，由rabbitmq的一台broker变为多台

2.kafka特点：吞吐量大-十万级，但延迟在ms级别；而rabbitmq吞吐量在万级，延迟在微秒级别
3.kafka功能：消息处理、分布式日志系统（可以常数时间时间定位到文件）
4.kafka原理
	(1)分区副本机制
		分区机制：解决单台服务器存储有限和并发限制的问题。
    	// 1. 为什么可以解决并发限制的问题：分成很多个分区后，放在不同的服务器下，可以减少对同一个服务器下的			  同一个分区的访问，提高并发能力~
    	副本机制：解决数据存储的高可用问题 (follower分片的唯一功能就是用作数据备份)
    	// 2.一个分区的副本不能放在同一个服务器上，是因为如果该服务器坏掉，该分区的高可用就不存在了，如果放在			不同的服务器中，当某台机器挂掉后，其他follower副本也能迅速”转正“，开始对外提供服务~
    	// 3.任何读写操作只能操作leader副本，而不能操作follower副本，在写完leader上的数据后，会立马同步到			follower副本上，leader上副本down掉时，follower副本会转正，成为leader                               	   原因：本质上是在可用性和一致性上的取舍，如果follower副本也可以提供服务，那么性能也会有提升，但是			  会存在类似数据库的幻读、脏读问题                                                                         案例：写入一条数据到kafka主题a，消费者b从主题a消费数据，却发现消费不到，因为消费者b去读取的是			   follower分区副本，最新消息还没写入。而这个时候，另一个消费者c却可以消费到最新那条数据，因为它消费		   了leader副本。
    (2) 消息不丢失机制
    	kafka集群：分区副本机制
    	生产者：ACK机制，发送消息后等待broker的确认
    		0：无需收到broker的消息确认，即可发送下一条，这种性能最高
    		1：leader副本写入成功就认为成功了
    		2：只有分区的所有副本（leader+follower）写入成功才认为写入成功
    	消费者：默认自动提交位移（先更新位移，再消费消息，可能消费者宕机没消费消息，但消息因为位移更新没了）
    		   需要改为手动提交位移，即消费者成功消费后手动提交
    (3) 消息存储及查询机制
    	存储：partition-> segment(.index、.log、.timeindex，按照offset的容量命名)
    	查询：来了一个offset，二分定位到segment段，查找该段对应的index文件，文件中是稀疏索引，每条记录包括			   offset索引值和对应该消息记录的物理地址，根据二分定位到后再去log文件中顺序查找
    (4) 生产者消息分发
    	默认使用实现Partitioner接口的DefaultPartitioner.class类中的partition方法
    	如果自定义类实现Partitioner接口的类就使用自定义类中的partition方法
    	策略：
    		如果用户指定分区，就不会调用partition方法
    		否则调用，如果指定key，取决于key的hash值，如果不指定key，则采用轮询分发
    (5) 消费者负载均衡
    	消费者在消费时需要指定消费者的组名。
    	同一个分区中的数据，只能被一个消费者组中的一个消费者所消费。不同组的消费者可以消费同一个分区的消息。
 目的是防止同一个组的消费者重复消费消息----并发问题。如果不同消费者消费同一个partition就需要加锁会影响性能。
```



## 2. Java基础

### 2.1 JavaWeb

```java
1. http格式：
	请求行 请求头 空白行 请求体
	响应行 响应头 空白行 响应体
	
2. Servlet的理解

	1) 是Java语言编写的服务器端程序,换句话说,Servlet就是运行在服务器上的Java类。
	   对于每个http请求打到tomcat服务器上,需要有一个servlet进行响应处理并对应逻辑，需要自行编写对应类(实现HttpServlet接口),也就是说一个项目下可以有很多个servlet处理http的请求，而每个http请求的路径应该在web.xml中定义。
	   
	2) servlet生命周期(只有http请求来的时候才会初始化该servlet容器):
       构造方法只被调用一次，当第一次请求Servlet时调用构造方法来创建Servlet的实例。
       init方法只被调用一次，当创建好Servlet实例后立即调用该方法实现Servlet的初始化。
       service方法被多次调用，每当有请求时都会调用service方法来用于请求的响应。
       destroy方法只被调用一次，当该Servlet实例所在的Web应用被卸载前调用该方法来释放当前占用
       的资源。
       
       ！！启动服务器并不会创建servlet对象，也不会执行其中方法，只有执行http响应时才会创建
       ！！启动服务器会创建filter对象，并执行init方法
     
     3) 每个servlet都有一个ServletConfig接口用于描述Servlet本身的相关配置信息，在初始化期间用于	将信息传递给Servlet配置对象。可以理解为这个config是单独为每个servlet使用的。
        而服务器会在启动时，为每个项目创建唯一的一个ServletContext对象，用于实现多个Servlet之间
	   的信息共享和通信。可以理解为n个servlet共享context对象里的信息。
3. filter过滤器是向 Web 应用程序的请求和响应处理添加功能的 Web 服务组件
   listener用来监听Servlet容器产生的事件并进行相应的处理
   
4.手写JDK动态代理
// 接口          
public interface JDKProxy {
    void test();
}

public class JDKProxyImpl implements JDKProxy {
    // 目标对象
    public static JDKProxy jdkProxy=new JDKProxyImpl();
    @Override
    public void test() {
        System.out.println("实现类的重写方法");
    }
    public JDKProxy createProxy(){
        // 生成目标对象的代理对象
        // 参数1：目标对象的类加载器，参数2：目标对象实现的接口，参数3：InvocationHandler接口的实现类
        return (JDKProxy) Proxy.newProxyInstance(jdkProxy.getClass().getClassLoader(), 		jdkProxy.getClass().getInterfaces(), new InvocationHandler() {
            @Override
            // proxy为当前的代理对象引用
            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                System.out.println("前动态代理的方法执行了");
                Object invoke = method.invoke(jdkProxy, args);
                System.out.println("后动态代理的方法执行了");
                return invoke;
            }
        });
    }

    public static void main(String[] args) {
        System.out.println(jdkProxy.getClass());
        JDKProxy jdkProxy1=new JDKProxyImpl().createProxy();
        jdkProxy1.test();
        System.out.println("--------");
        jdkProxy.test();
    }
}
```

### 2.2 JavaSE

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/stringtable%E4%BE%8B.png" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/stringtable%E4%BE%8B_%E8%A7%A3%E6%9E%90.png" style="zoom:67%;" />

```java
1.hash冲突的解决方法
    开放地址法：
    	线性探测散列：即某一个位置被占就往后跳一个格子看是否有位置，没有就继续跳
    	平方探测散列：增量依次是，1方，-1方，2方，-2方...
    链地址(就是链表，HashMap的处理方式)
    再哈希法：当hash冲突时，用另一个hash函数计算hash值
    
2.为什么重写 equals 时必须重写 hashCode 方法？
    如果两个对象相等，则 hashcode 一定也是相同的，那么调用equals方法一定返回true，如果重写了equals方法，hashcode没有重写，此时会对象相等但hashcode不等的情况，以hashset为例，放入这两个对象的时候会先计算hashcode，hashcode都不等了就会放入不同的桶中，但是两个对象实际是相等的，应该放在同一个桶中。
    
3.JDK JRE JVM的关系
    JDK = JRE + (javac,javap等一些列工具)
    JRE = JVM + 运行类库
    
4.Java 是编译与解释共存的原因
    编译：1) java文件需要先编译成class文件 2) JVM JIT编译热点代码 变成机器码存入方法区中
    解释：执行器一条一条字节码解释执行
    
5. java的泛型是伪泛型，在运行期间，所有的泛型信息都会被擦掉
    List<Integer> list = new ArrayList<>();
    //这里直接添加会报错
    list.add("a");
    Class<? extends List> clazz = list.getClass();
    Method add = clazz.getDeclaredMethod("add", Object.class);
    //但是通过反射添加，是可以的
    add.invoke(list, "kl");

6.关于String
    String类由final修饰，不可被继承，1.9开始用final byte数组存储
    // 常量池
    1) 定义：
        通过字面量的方式（区别于new）给一个字符串赋值，此时的字符串值声明在字符串常量池中
        字符串常量池是不会存储相同内容的字符串的
        String的String Pool是一个固定大小的Hashtable，默认值大小长度是1009。如果放进String Pool的		   String非常多，就会造成Hash冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用		   String.intern时性能会大幅下降。
    2) 使用：
    	直接使用双引号声明出来的String对象会直接存储在常量池中。 
		如果不是用双引号声明的String对象,可以使用String提供的intern()方法，会将堆区对象的地址放入池中
    	Java7以前字符串常量池放在永久代,Java7移入堆中(静态变量也移入堆中)
    3) 关于intern方法：
    	当调用intern方法时，如果池子里已经包含了一个与这个String对象相等的字符串，正如equals(Object)	方法所确定的，那么池子里的字符串的引用会被返回。否则，这个String对象的引用地址会被copy一份并添加到池中
    	Interned string就是确保字符串在内存里只有一份拷贝，这样可以节约内存空间

7.接口和抽象类的区别
    类：抽象类单继承，接口多实现
    变量：抽象类可以有成员变量，接口只能有常量（默认public static final修饰）
    方法：抽象类有构造方法，可以有成员方法，抽象方法可有可无
    	 接口无构造方法，只有抽象方法，必须被重写
    // 关于接口，1.8在接口中允许有default修饰的非抽象方法，以及静态方法，1.9允许私有化
    // 而在1.8之前，接口中变量都是public static final修饰，方法都是public abstract修饰
8.object中的方法：
    hashcode、equals、wait、notify、toString、getClass、finalize、clone
    clone默认是浅拷贝，Object类里面没有实现cloneable接口，所以在使用这个方法时，实体类需要实现cloneable接口，并重写clone方法，默认写super.clone()就行

9.// 反射
    利用反射运行时分析类并执行类中方法
    获取class对象的方法：
    1) 类型.class
    2) 引用/对象的.getClass()
    3) Class.forName("类全路径") // 会对类进行静态初始化
    4) ClassLoader.loadClass("类全路径") // 并不会对类进行静态初始化
     
10.反射的实现原理： 
	反射类及反射方法的获取,都是通过从列表中搜寻查找匹配的方法,所以查找性能会随类的大小方法多少而变化 		每个类都会有一个与之对应的Class实例，从而每个类都可以获取method反射方法，并作用到其他实例身上； 
	反射也是考虑了线程安全的，放心使用
	反射使用软引用relectionData缓存class信息，避免每次重新从jvm获取带来的开销； 
	反射调用多次生成新代理Accessor, 而通过字节码生存的则考虑了卸载功能，所以会使用独立的类加载器； 
	当找到需要的方法，都会copy一份出来，而不是使用原来的实例，从而保证数据隔离； 
	调度反射方法，最终是由jvm执行invoke执行；
11.静态代理和动态代理的区别：
       JDK动态代理的过程：首先有三个东西，接口、目标对象、代理对象，代理对象通过Proxy.newInstance(目标对象的类加载器，目标对象的接口，InvocationHandler的实现类)得到，当代理对象调用接口中的方法时，就会调用InvocationHandler中重写的invoke方法进行动态增强
       但JDK动态代理只能代理实现了接口的类，Cglib可以代理没有实现接口的类也可以实现代理接口的类
       //区别：
        静态代理中，接口一旦增加方法，代理类也需要重写方法，任务量很重，动态代理不用
        动态代理的代理类字节码是运行时JVM自动生成并加载的，静态代理的代理类class文件编译后就有了
12.ArrayList分析
        1)和linkedList的区别：一个数组一个双向链表，其次围绕增删查改的时间复杂度来说，空间复杂度arraylist体现在需要预留一部分空间，linkedlist的复杂度在于每个节点需要维护前后节点的地址
        2) 初始化：如果指定了容量则初始化该容量的Object数组，否则该数组为空
        3) 扩容分析:如果此时的size等于数组长度，即需要扩容了(minCapacity=size+1)，将minCapacity传入扩容方法，会计算newCapacity为此时数组长度的1.5倍，Ⅰ如果还是小于minCapacity，那么扩容大小应为minCapacity，Ⅱ 如果newCapacity大于MAX_ARRAY_SIZE，判断minCapacity是否大于MAX_ARRAY_SIZE，如果大于newCapacity=Integer.MAX_VALUE，小于newCapacity=MAX_ARRAY_SIZE，最后返回newCapacity。扩容是调用Arrays.copyOf()方法的。
            //看下面这个
           当数组为空时，第一次加入一个元素，会调用grow方法扩容，计算newCapacity为minCapacity的1.5倍，但此时minCapacity为0，newCapacity仍小于等于minCapacity，所以此时会让newCapacity=10。此后直到添加到11个元素，又需要扩容了，newCapacity=1.5*数组length，如果newCapacity大于MAX_ARRAY_SIZE，就需要判断minCapacity是否大于MAX_ARRAY_SIZE，如果仍然大于它，newCapacity=Integer.MAX_VALUE，否则newCapacity=MAX_ARRAY_SIZE。最后返回newCapacity。扩容是调用Arrays.copyOf()方法的
            
13.HashMap的分析：
         初始化为16，每次扩容2倍，如果指定容量大小，则会把该容量变成2的幂次方，默认负载因子为0.75，当总容量达到12个时候就会resize，涉及到rehash比较耗费性能
         JDK1.8 及以后的HashMap在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64(即大于等于64会转化红黑树)，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间
         //hashmap长度是2的幂次方的原因：
         当计算出对象的hashcode后，需要计算在数组下标中的位置，即hashcode%length,如果length长度为2的幂次方，hashcode%length == hashcode&(length-1),这种采用位运算的方式会加快运算
         // 并发情况下hashmap可能会导致链表死循环，主要是rehash中的transfer方法的问题
   //扩容分析:put方法实际调用了putval方法
   首先第一次put时候会触发resize为16，然后通过(n - 1) & hash计算出数组下标即桶的位置。
   如果该位置无数据则直接创建新节点插入，
   如果没有进行接下来的判断， 
      Ⅰ如果该位置的hash值以及key和待插入的key和hash相等，代表这就是我们要找的entry， 
      Ⅱ如果该节点是树节点，调用红黑树插入 
      Ⅲ 如果不是树那就是链表，采用尾插法，循环遍历，如果找到了key的hash并且key相等的entry，遍历结束，如果找到末尾，则插入新节点，并判断当前如果新插入的元素是第八个的话就会调用treeifyBin，决定是否转化成红黑树(table数组长度大于等于64才可以转换)
      如果找到的entry节点不为空，就把newval替代给oldval
   最后如果插入元素大于了threshold，就会调用resize方法
```

### 2.3 JVM

![](https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/JVM%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%E5%9B%BE.png)

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E.png" style="zoom:67%;" />

![](https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/class%E5%92%8Cclassloader.png)

![](https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E6%96%B9%E6%B3%95%E5%8C%BA_JDK6.png)

![](https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E6%96%B9%E6%B3%95%E5%8C%BA_JDK7.png)



![](https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E6%96%B9%E6%B3%95%E5%8C%BA_JDK8.png)



#### 2.3.1 内存区域

```java
1.运行时数据区
    (1) 程序计数器
    	如果是java方法，存有正在执行的字节码指令地址
    	如果是本地方法，计数器为空
    (2) 虚拟机栈
    	虚拟机栈可以理解为一个集合，该集合中可以包含许多个栈，每个栈对应一个线程，这个栈中包含许多栈帧，栈帧对应线程中的一个方法，每个栈帧包括局部变量表、操作数栈、动态链接、方法返回地址。
        1) 局部变量表以局部变量槽(slot)表示，一个槽在HotSpot中占用32位，编译后，slot的总数就确定好了，在方法表的Code属性中可以看到。
    	2) 操作数栈的最大深度编译后在方法表的Code属性中可以看到
    	3) // 动态连接是个什么玩意？
    	4) 方法返回地址：栈帧会保存主调方法的PC计数器的值，正常退出后该值就是returnAddress；方法异常退出后是通过异常表来确定的，栈帧中一般不会保存该信息。
    (3) 本地方法栈
    (4) 堆
    	目的：存放对象实例
    	"几乎"所有的对象都在这里分配内存，但一些优化手段如：栈上分配、标量替换导致一些对象在栈上分配内存，具体可以看《深入理解java虚拟机》P417
    	堆中存在TLAB(Thread Local Allocation Buffer)即线程分配缓冲
    	// !!!总结：Java将堆细分的目的就是更好的分配内存或者回收内存
    (5) 方法区(只是一个概念，具体实现每个虚拟机不同)
    	1) 内容：具体见上图，其中运行时常量池存有所有类class文件的常量池表，常量池表包括字面量和符号引用，符号引用翻译出来的直接引用也存入运行时常量池。
    	2) 目标：回收目标主要是类型的卸载，但是类型的卸载条件十分苛刻 (见上图)
    	3) 1.8元空间取代永久代的原因：随着动态类加载的情况越来越多，永久代内存变得不太可控，如果设置小了，系统运行过程中就容易出现内存溢出，设置大了又浪费内存；而元空间移入本地内存，可以通过MetaSpaceSize设置元空间的初始值，在不超过MaxMetaSpaceSize大小的情况下，垃圾收集器会动态调整该值，以此满足元空间的正常运行。
    // 常量池的类型：1) 常量池表 2) 包装类常量池 3) 字符串常量池(1.7和静态变量一起移入堆中，方便回收字符串常量) 4) 运行时常量池(1和2都在此) 
    // 字符串常量池调整的原因：永久代的空间较小，加上GC频率低，容易OOM
    (6) 直接内存(不是JVM运行时数据区的一部分)
    	用于NIO中，使用Native函数库分配堆外内存，然后通过java堆中的DirectByteBuffer对象操纵这块堆外内存，避免了Java堆和Native堆来回复制数据。直接内存和元空间一样都存在本地内存中。
    
2.对象的创建过程
    (1) 遇到new 指令时，首先定位到该类的符号引用，并检查该类是否被加载、验证、准备、解析和初始化过，没有就执行类的加载过程
    (2) 给对象分配空间。分配空间有指针碰撞和空闲列表两种方式。需要考虑到并发的问题，可以用CAS和TLAB解决。
    (3) 给对象实例数据部分初始化为0
    (4) 设置对象头
    (5) 执行<init>方法
    
3.对象的结构
    (1) 对象头
    	// 根据锁标记可动态调整MarkWord的内容
    	1) MarkWord：hashcode、GC分代年龄、锁状态、锁标记
    	2) 类型指针
    	3) [如果是数组这里记录数组长度]
    (2)	实例数据
    (3) 对齐填充：保证对象大小为8字节

4.对象的定位方式
    (1) 句柄：在堆中维护一个句柄池，包含两部分，一部分指向对象实例数据，一部分指向元空间的类结构
    (2)	直接引用：包含实例数据和对象头中指向类结构的类型指针

5.OOM的可能情况
    (1) 堆：dump出堆转储快照分析是内存泄漏还是内存溢出,如果多次GC堆依然增大可能是内存泄漏了,如果是泄露,可通过工具查看泄露对象的GCroots引用链,找到代码的具体位置;如果是溢出可以适当调整参数设置并且检查代码是否有不合理地方
    (2) 方法区：使用元空间实现后，如果运行时生成大量的类，才有可能导致OOM，不过在本地内存中上限较高，出现几率不大，也可通过MetaSpaceSize设置。
    (3) 栈：HotSpot虚拟机栈不支持动态扩展,只有在多线程情况下,某一线程在申请栈空间不够时才会OOM,可以减少堆的大小和减小每个线程分配得到栈的容量来换取更多的线程;如果是在线程运行过程中一直调用方法，只会报stackoverflowerror
	(4) 直接内存：当heap dump文件很小，无明显异常，程序中使用了NIO类似的方法，可能就是直接内存溢出了。
    
6.JVM常见参数设置
    -Xms(堆小)、-Xmx(堆大)、-Xss(栈)、-XX:MetaspaceSize(元空间初始大小)、-XX:MaxMetaSpaceSize(元空间最大,默认和本地内存一样)
    
7.内存泄漏出现的原因
(1)单例对象，这样存活时间很长的对象引用了使用时间很短的对象，那么这个被引用的对象就一直不能被回收,单例的生命周期和应用程序是一样长的，所以单例程序中，如果持有对外部对象的引用的话，那么这个外部对象是不能被回收的，则会导致内存泄漏的产生；
(2)各种连接资源对象，数据库连接(dataSourse . getConnection())，网络连接(socket)和io连接必须手动close，否则是不能被回收的，这些资源连接都要在finally{}中手动关闭；
(3)静态集合类
    static final ArrayList ARRAY_LIST = new ArrayList();
    public void addObject() {
        Object obj = new Object();// 原本obj对象对应的栈帧一出栈obj对象就会消除，未逃逸
        ARRAY_LIST.add(obj);     // 但是由于有静态集合的引用所有一直不能被消除，就出现了内存泄漏
    }

```

#### 2.3.2 内存分配策略与垃圾收集器

```java
// 以下两个如何 属于标记过程
1.如何判断堆中对象可回收
	(1) 可达性分析：
    	由GCRoots找可达对象，如果不可达，对象被第一次标记，随后收集器判断是否有必要执行finalize方法
    	有无必要是说该对象如果执行过finalize方法或者没有重写过该方法就无必要
    	如果有必要执行finalize方法，该对象就会被放在F-Queue队列中，稍后会有JVM低调度优先级的Finalizer线程去执行它们的finalize方法，如果还是没有逃脱就会被回收
    
	(2) GCRoots都有哪些(先记这6个)
    	栈中局部变量
    	静态变量(类变量0)
    	字符串常量池的引用
    	class对象和系统类加载器对象
    	同步锁持有的对象
    	跨代引用的对象！！！
    
    (3) 引用的类型
		强引用
		软引用
    		只被软引用指向的对象当内存快溢出的时候才会被清理掉
    		1) 高速缓存：使用缓存的同时，不会耗尽内存
    		2) 在反射中调用 reflectionData(), 获取保存的信息，使用软引用保存，从而使内存不够可以回收，ReflectionData静态类中存有Method、Field、Constructor，每当通过反射获取这三个 “东西”时，先从ReflectionData中查找，没有再去JVM中查找
		弱引用(WeakHashMap) 只被弱引用指向的对象，只要发生GC就会被清理掉
 		虚引用 对象持有虚引用跟没有引用是一样的，唯一的目的就是在对象被回收的时候收到一个系统通知。虚引用必须和引用队列一起使用。虚引用在创建时必须提供一个引用队列作为参数。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象后，将这个虚引用加入引用队列，以通知应用程序对象的回收情况。//由于虚引用可以跟踪对象的回收时间，因此，也可以将一些资源释放操作放置在虚引用中执行和记录。
  
2.如何判断方法区可回收(元空间)
	//条件苛刻，字符串常量池和静态变量1.7已移入堆中无需考虑，回收的是类型和运行时常量池中废弃的常量
    只要常量池中的常量没有被任何地方引用，就可以被回收。
    
    类型的回收：
    (1) 类的实例都被回收(包括该类和派生子类的实例)
    (2) 该类的类加载器被回收
    (3) 该类的class对象没有被任何地方引用
    
      回收Eden时候，还有old区的部分，具体就是加入Eden中卡表脏所指向的old部分(每次更改引用所指向的时候都会通过写后屏障来更新记忆集，避免gc效率过低)

3.垃圾回收算法
    // 引出分代假说 强分代和弱分代假说，弱分代是说所有对象朝生夕灭，强分代说熬过越久的对象越难以消亡
    // 所以需要对堆分为新生代，老年代，针对不同代收集引出minorGC(只收集新生代)、majorGC(只收集老年代，CMS会这样做，但是有的是指整堆收集)、MixedGC(新生代和部分老年代，G1会这么做)，fullgc(堆+方法区)
    (1) 标记清除：效率低，有碎片 // 老年代用 CMS
    (2) 标记复制：空间分为一半一半，某一次只使用一块,这块使用完了就会把存活的复制到另一块,缺点就是空间浪费多。具体实现呢，hotspot采用Eden、survivior1、survivor2(8:1:1)来分配新生代，每次使用Eden和一个survivor，GC后存活的对象放入到另一个survivor，如果存活对象过多，使用空间分配担保机制放入老年代 // 新生代用
    (3) 标记整理：在标记清除之上，移动存活对象到另一端 // 老年代用

    // 总结:老年代剩的存活对象多，标记复制需要来回移动对象不适合老年代，而新生代gc剩余对象通常很少老年代可以采用标记清除和标记整理算法，标记清除的停顿时间短，但由于频繁需要整理空闲链表，导致吞吐量下降，而标记整理延迟高一些，但吞吐量好于标记清除
   
4.HotSpot实现的算法细节：
    (1) 由根节点枚举 // 就是找GCRoots，需要stw，
-> 根节点怎么找 // 不能逐一扫描，用到了OopMap数据结构，里面存放了栈或者寄存器哪里放了引用
-> OOP在哪里 // 安全点才会记录
-> 安全点是什么 //安全点是GC的执行位置(让用户线程都停顿下来),此时要gc，需要让用户线程都到安全点才行，那么问题来了，如何让用户线程在发生gc时都到达安全点，分为抢先式中断(废弃)和主动式中断
    // 抢先式中断首先暂停所有用户线程，如果线程还未在安全点上继续执行，直到到了安全点上
    // 主动式中断在需要gc时会设置一个中断标志位，而用户线程在安全点上会轮询这个标志位，即自动中断
-> 安全区域 // 如果用户线程被阻塞就不会到安全点处轮询标志位了，即无法知道中断标志位的状态，所以可以对用户线程设置一个安全区域，当用户线程在此区域中时，垃圾收集器就会知道这个区域引用关系不会发生变化，可以回收啦，当线程即将走出安全区域时，判断此时JVM是否还需要执行停止用户线程的操作，如果不需要，直接走出去就完事了,需要就还得等一会
    (2) 跨代引用如何实现 
-> 记忆集 //具体实现(卡表) 
-> 卡表怎么维护 -> 写后屏障 // 这个操作是同步的
    (3) 并发的可达性分析 
    目前CMS和G1收集器会用到，主要为了解决用户线程和垃圾线程可以一起工作的问题，主要是漏标，即活对象给标死了
    漏标的两个必要条件
    	1) 多了黑到白
    	2) 从会到该白对象的引用关系全被删除
-> 三色标记 // 黑白灰
-> 增量更新、原始快照 // 解决 1)就是增量更新，解决 2)就是原始快照

5.垃圾收集器
    七个经典收集器
    (1) serial + serial old // 全程stw
    (2) parallel scavenge + parallel old
    	相比serial是并行收集，但过程都是stw的。parallel scavenge目标是缩短停顿时间的同时，达到可控制的吞吐量(用户代码时间/用户代码时间+垃圾收集时间)，吞吐量高代表着处理器资源利用的好。但是设置停顿时间越短，会导致收集次数增加，变向导致垃圾收集时间增加，吞吐量降低。
    	参数：-XX:MaxGCPauseMills 最大停顿时间
              -XX:GCTimeRatio 吞吐量大小
         	  -XX:UseAdaptiveSizePolicy 即不需要人工指定新生代中Eden与Survivor的比例，自动调节满足吞吐量				和停顿时间的设置
    (3) ParNew + CMS
         ParNew相比serial是并行收集。
         CMS的初衷和目的：为了消除Serial收集器在Full GC周期中的长时间停顿。
         // CMS是如何用增量更新解决的
	(4) G1
        G1设定的目标是在延迟可控的情况下获得尽可能高的吞吐量，G1（Garbage-First）是一款面向服务端应用的垃圾收集器，主要针对配备多核CPU及大容量内存的机器，以极高概率满足GC停顿时间的同时，还兼具高吞吐量的性能特征
    G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region
    G1中提供了三种垃圾回收模式：Young GC、Mixed GC和Full GC，在不同的条件下被触发
    G1的初衷就是要避免Full GC的出现
    // G1是如何用原始快照解决的
    缺点：
    场景:面向服务端应用，针对具有大内存、多处理器的机器
6.FullGc的场景  
     // 还没有总结好 等把G1和CMS总结好
	
        
7.内存分配回收策略 // 讲的都是新生代里分配、以及新生代GCh
    (1) 对象优先在新生代的Enen分配，Eden不够就会触发一次MinorGC
    (2) 大对象直接进入老年代
    (3) 长期存活直接进入老年代：默认经历了15次GC会进入老年代，但如果survivor空间中相同年龄所有对象大小的总和大于survivor空间的一半，年龄大于等于该对象的就会直接进入老年代
    (4) 空间分配担保：在发生MinorGC之前，会判断如果老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行MinorGC，否则进行FullGC
        
8.如何选择垃圾回收器
	● 如果单核内存小，请选Serial GC(客户端)；
	● 如果你想要最大化应用程序的吞吐量，请选Parallel GC；
	● 如果你想要最小化GC的中断或停顿时间，请选CMS GC。
    
STW的例子：根节点枚举，标记整理内存碎片,CMS初始标记和重新标记，G1除并发标记都要STW
```

##### 2.3.2.1 CMS

CMS的回收过程 https://www.jianshu.com/p/2a1b2f17d3e4

CMS详细笔记 https://segmentfault.com/a/1190000018820219

System.gc() 解释：http://lovestblog.cn/blog/2015/05/07/system-gc/

这里必须提到CMS GC，因为这是解释并行Full GC和正常Full GC的关键所在，CMS GC我们分为两种模式background和foreground，其中background顾名思义是在后台做的，也就是可以不影响正常的业务线程跑，触发条件比如说old的内存占比超过多少的时候就可能触发一次background式的cms gc，这个过程会经历CMS GC的所有阶段，该暂停的暂停，该并行的并行，效率相对来说还比较高，毕竟有和业务线程并行的gc阶段；而foreground则不然，它发生的场景比如业务线程请求分配内存，但是内存不够了，于是可能触发一次cms gc(并发模式失败导致的)，这个过程就必须是要等内存分配到了线程才能继续往下面走的，因此整个过程必须是STW的，因此CMS GC整个过程都是暂停应用的，但是为了提高效率，它并不是每个阶段都会走的，只走其中一些阶段，这些省下来的阶段主要是并行阶段，Precleaning、AbortablePreclean，Resizing这几个阶段都不会经历，其中sweep阶段是同步的，但不管怎么说如果走了类似foreground的cms gc，那么整个过程业务线程都是不可用的，效率会影响挺大。

promotion failed和concurrent mode failure的触发原因有啥不同？

- promotion failed是说，担保机制确定老年代是否有足够的空间容纳新来的对象，如果担保机制说有，但是真正分配的时候发现由于碎片导致找不到连续的空间而失败；
- concurrent mode failure是指并发周期还没执行完，用户线程就来请求比预留空间更大的空间了，即后台线程的收集没有赶上应用线程的分配速度(这种情况下，当新生代对象去老年代时是担保失败了，引发concurrent mode failure，如果担保成功但是去老年代里一看发现还是没有足够空间就会promotion failed)

##### 2.3.2.2 G1

#### 2.3.3 Class文件结构

**该部分主要是javac编译后的格式，JVM还没有对其进行处理**

```java
1.魔数 cafebaby 标志该文件为class文件
2.版本号
3.常量池表
    在常量池入口处有constant_pool_count，表示常量池的大小
    字面量和符号引用(符号引用都包括...)
4.文件的访问标志 // 类还是接口还是枚举还是注解，包括修饰这些的关键字，如果为真就累加起来
5.(1) 类索引：类或接口在常量池中的符号引用
  (2) 父类索引：父类的符号引用
  (3) 接口索引：实现的全部接口的符号引用
6.字段表集合
    包括类级变量和实例级变量(不包括局部变量)
    (1) 访问标志：和文件的访问标志一，就是修饰字段的关键字，如public、final、static等(各标志的累加值)
    (2) 字段的简单名称：就是无类型和参数修饰的字段或者方法的名称(符号引用)
    (3) 描述符(符号引用)：如果是字段就是字段类型
    		  如果是方法就是参数类型+返回值类型
    // 例：private int m 
    // 访问标志:private 简单名称：m 描述符：I/
    //    private String[] inc(int m)
    // private,inc,(I)[Ljava/lang/String
    // 字段访问到常量池中的符号引用时,可以定位到该字段的类的符号引用,也就是说在解析成直接引用后可以访问到类的信息
    (4) 属性表信息(可以没有)
    	字段属性表中有ConstantValue属性。
    	Oracle的Javac编译器中，如果是实例变量直接在<init>中赋值，如果同时被final和static修饰，并且是基本类型或者String类型就会在字段表中加入属性ConstantValue进行赋值，如果没有final或者并非基本类型和String就会在<clinit>中赋值
7.方法表集合
    方法表中的属性表信息有Code属性，存放方法中的代码
    在code属性中：LineNumberTable属性是用来描述Java源码行号与字节码行号之间的对应关系。这个属性可以用来在调试的时候定位代码执行的行数;还有 LocalVariableTable属性
8.属性表集合(也就是说class文件、字段表和方法表中都可以有属性表)
```



#### 2.3.4 类加载

**JDK9之前：**

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E5%85%B3%E7%B3%BB.png" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E5%90%AF%E5%8A%A8%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8.png" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E6%89%A9%E5%B1%95%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8.png" style="zoom: 67%;" />

​															**系统类加载器负责classpath下的加载**

**JDK9开始：**

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/JDK9%E7%9A%84%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E5%85%B3%E7%B3%BB.png" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E5%90%AF%E5%8A%A8%E7%B1%BB%E8%B4%9F%E8%B4%A3%E6%A8%A1%E5%9D%97.png" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E5%B9%B3%E5%8F%B0%E7%B1%BB%E8%B4%9F%E8%B4%A3%E6%A8%A1%E5%9D%97.png" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%B1%BB%E8%B4%9F%E8%B4%A3%E6%A8%A1%E5%9D%97.png" style="zoom:67%;" />

**JVM开始对class文件进行处理了**

```java
1.类初始化的时机
    // 类的生命周期：加载、验证、准备、解析、初始化、使用、卸载
    // 其中加载、验证、准备、初始化的开始顺序一定是这样，进行顺序以及完成顺序没有固定，是因为这些阶段都存在交叉混合进行，只是开始顺序如上述所说。而解析阶段不一定，加载过程可能解析，也有可能在运行阶段进行解析。
    // 关于加载阶段并没有强制要求，但是初始化严格规定有且只有六种情况需要立马执行类的初始化(加载验证准备自然已经执行了)
    主动使用：(先记前5个)
    (1) new、putstatic、getstatic、invokestatic 四个字节码指令
    (2) 使用reflect包下的方法对类型反射调用时 //反射
    (3) 初始化类时，如果父类还没有初始化，需要先对父类初始化 // 父类
    (4) main()方法的主类 // 主类
        // 接口正常不会初始化，只有用到的时候才会被初始化，如引用接口中的静态常量，接口不可以有static{}块，但是可以有<clinit> 方法 (接口不是只能有static final修饰的字段吗，为什么还有成员变量，书P266,感觉写的有问题？)
    	// 回答上面问题:书上写的没有错，接口字段都是public static final没错，对于接口中的类字段如果带有属性ConstantValue，则不会生成<clinit>方法，否则会生成，例:Test t=new Test()；而是否带有ConstantValue属性，则看字段类型是不是基本类型或者String类型(Integer不算基本类型)，带有该属性的字段在类加载过程中的准备阶段就会赋值，无需等到<clinit>方法，所以不需要初始化！！！
    (5) 接口中有default修饰的非抽象方法，有类实现了该接口，需要在该类初始化前初始化该接口 // 接口
    (6) MethodHandle对应的类没有初始化
    
    被动使用：
    (1) 子类引用父类中的静态字段，只有父类会发生初始化,子类不会(是否会发生子类的加载看JVM具体实现,无严格要求)
    (2) Father[] f = new Father[5] // Father类不会初始化 
    (3) 引用类中static final 的字段，该字段在准备阶段会被赋值，所以不需要初始化
2.类加载过程
    (1) 加载 // 对应类加载器的作用流程
    	1) 获取类的二进制字节流
    	2) 将二进制字节流所代表静态存储结构转化为方法区的运行时数据结构
    	3) 堆区生成这个类的class对象作为方法区这个类的各种数据访问入口
    	加载与连接的部分动作(如一部分的字节码文件格式验证动作)是交叉进行的，加载还没有完成，连接可能已经开始，但是这些夹在加载中的动作，仍然属于连接的一部分
    (2) 验证：
    	1) 文件格式验证：魔数、版本号等
    	2) 字节码验证：主要是方法中的字节码的检查，不能危害虚拟机
    	3) 符号引用验证：如通过字符串描述的全限定名是否可以找到对应的类，目的确保解析正常进行
    (3) 准备：仅为类变量分配内存并设置初始值，通常情况下赋值为0等等，但如果类字段的属性表中存在ConstantValue属性，在准备阶段变量值就会被初始化为ConstantValue中指定的属性值(这里和class文件结构呼应上了，还有就是我认为final static 变量也应该在堆中分配内存，只不过是在准备阶段就被赋值了，其他类字段在初始化<clinit>方法中赋值)
    (4) 解析：
    	解析就是符号引用转化为直接引用，如果有了直接引用，说明目标一定在JVM中了
    	并未规定解析具体发生的时间，有17个操作符号引用的字节码指令，在执行指令前之前需要对符号引用进行解析，所以JVM自行决定是在类加载就解析，还是等到符号引用用到时才解析。
    	// 四种常见的解析：类、字段、类方法、接口方法 P275
    (5) 初始化：
    	<clinit> 方法是类变量的赋值动作和静态语句块合并而成
3.类加载器
    // 类加载器的功能对应类加载过程的加载阶段  
    (1) 定义：ClassLoader是Java的核心组件，所有的Class都是由ClassLoader进行加载的，ClassLoader负责通过各种方式将Class信息的二进制数据流读入JVM内部，转换为一个与目标类对应的java.lang.Class对象实例。然后交给Java虚拟机进行链接、初始化等操作。因此，ClassLoader在整个装载阶段，只能影响到类的加载，而无法通过ClassLoader去改变类的链接和初始化行为。至于它是否可以运行，则由Execution Engine决定。
    
    (2) 两个类相等的条件：class文件相等，并且类加载器相同
    (3) 种类：
    	1) 启动类/引导类加载器(Bootstrap ClassLoader)
    		C++编写的，在JVM内部已经实现，它用来加载Java的核心库(JAVAHOME/jre/lib/rt.jar)
    		是2) 3) 的"父类"加载器
    	2) 扩展类加载器(Extension ClassLoader)
    		java编写，继承于ClassLoader抽象类，从JAVAHOME/jre/lib/ext下加载类库。如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载
    	3) 应用程序/系统类加载器(AppClassLoader)
    		java编写，继承于ClassLoader抽象类，加载环境变量classpath下的类库
    		是默认的系统类加载器，也是用户自定义类加载器的默认父加载器
		// 上述父类关系并不是继承的关系，而是包含的关系，在Launcher类中定义了2) 3)的类加载器

4.双亲委派机制
    (1) 定义：如果一个类加载器在接到加载类的请求时，它首先不会自己尝试去加载这个类，而是把这个请求任务委托给父类加载器去完成，依次递归，如果父类加载器可以完成类加载任务，就成功返回。只有父类加载器无法完成此加载任务时，才自己去加载
    (2) 本质：规定了类加载的顺序是：引导类加载器先加载，若加载不到，由扩展类加载器加载，若还加载不到，才会由系统类加载器或自定义的类加载器进行加载
    
    ClassLoader被SecureClassLoader继承，SecureClassLoader被URLClassLoader继承
    ExtClassLoader和AppClassLoader都继承了URLClassLoader，是sun.misc.Launcher的静态内部类
    URLClassLoader中重写了findclass方法，所以我们在自定义类加载器时可以直接继承URLClassLoader类
    (3) ClassLoader中的方法
    	   // 已在ClassLoader中实现，为双亲委派的逻辑
		1) public Class<?> loadClass(String name) 
    		synchronized (getClassLoadingLock(name)) {
            // 看是否该name对应的类已被加载
            Class<?> c = findLoadedClass(name);
            if (c == null) {
                try {
                    if (parent != null) {
                        // 递归查询
                        c = parent.loadClass(name, false);
                    } else {
                        c = findBootstrapClassOrNull(name);
                    }
                } catch (ClassNotFoundException e) {
                    // ClassNotFoundException thrown if class not found
                    // from the non-null parent class loader
                }
                if (c == null) {
                    // 父类没找到自己找
                    c = findClass(name);
                }
            }
    		// 链接阶段：验证准备解析
            if (resolve) {
                resolveClass(c);
            }
            return c;
        }
    	   // 未在ClassLoader中实现，loadClass中调用该方法查找name的Class类
		2) protected Class<?> findClass(String name) 
    	   // 已在ClassLoader中实现，将byte字节流解析成JVM能够识别的Class对象
		3) protected final Class<?> defineClass(String name, byte[] b,int off,int len) 
   		通常findclass和defineclass一起使用，自定义类加载器继承ClassLoader时，重写findclass方法，当调用loadclass方法没有获得class对象时，会执行自己的findclass方法完成类加载，同时也符合双亲委派模式
    
	(4) 注意的地方：
    	1) Class.forName(String name)：静态方法，根据传入的类的全限定名返回一个Class对象。该方法在将Class文件加载到内存的同时，会执行类的初始化
           classLoader.loadClass()：实例方法，该方法将Class文件加载到内存时，并不会执行类的初始化，直到这个类第一次使用时才进行初始化。 
        2) 如果重写loadclass方法破坏双亲委派逻辑想要加载核心类库是不行的，因为不管任何类加载器都要调用defineclass，该方法会执行preDefineClass()，提供了对核心类库的保护
	
    (5) 优势：1) 避免类的重复加载 2) 防止核心API被随意篡改 
    (6) 劣势：即顶层的ClassLoader无法访问底层的ClassLoader所加载的类，设置了线程上下文加载器(ContextClassloader)默认是AppClassLoader,但设置上下文加载器的同时等同于破坏了双亲委派的逻辑
            
    (7) 破坏双亲委派：1) 设置环境上下文类加载器 2) OSGI的热替换，加载模型变成网状结构，大都平级加载，当一个模块需要替换掉时，就连同该模块的类加载器一同替换掉 3) 模块化也算
    (8) //什么是模块化，模块化后的加载机制有何不同？？
       	JDK9多了模块化，但本质上和之前一样都是三层的双亲委派。
        上述都是JDK9之前的双亲委派加载器
        模块化就是一个模块下有很多包，每个包下才有很多个java文件。
        ！！！机制：移除扩展类加载器，变为平台类加载器，当平台及应用程序类加载器收到类加载请求，在委派给父加载器加载前，要先判断该类是否能够归属到某一个系统模块中，如果可以找到这样的归属关系，就要优先委派给负责那个模块的加载器完成加载。
            
5.方法调用的指令
    (1) 解析
            方法在编译后就确定下来，可以直接转换为直接引用，属于解析！
            如静态方法、私有方法、<init> 、父类方法、final方法(但使用invokevirtual)
            invokespecial 私有方法、<init> 、父类方法
            invokestatic 调用static方法
    (2) 分派(和解析说两个维度上的筛选，并不是二选一的排他，如静态方法在加载时就会被解析，也可能存在重载)
            静态分派:依照静态类型作为判断依据 -----重载
            动态分派:依照实际类型作为判断依据 -----重写
            静态类型和动态类型的区别：二者在程序中都会发生变化，但是静态类型的变化是在编译时就可以确定的，如强制类型转换，但是实际类型的变化需要依照程序的逻辑，运行时才会知道
            // java是静态多分派，动态单分派的语言
            invokevirtual指令运行时解析的过程：
                1) 找到操作数栈顶第一个元素的实际类型C
                2) 在C中找到与常量池中简单名称和描述符都相等的方法,找到就返回这个方法的直接引用
                3) 没找到就按照继承关系由下到上依次查找
            invokevirtual 调用对象的实例方法，根据对象的实例类型进行分派(静态(重载)和动态(重写))
            invokeinterface 调用接口方法，运行时搜索一个实现了这个接口方法的对象
            动态分派的实现：由于动态分派选择方法需要在接收者类型(实际类型)中搜索目标方法并返回直接引用，所以措施是在方法去建立一个虚方法表。虚方法表会在类加载过程中准备阶段进行。
                
6.关于编译器的基础知识
    (1) JIT及时编译器：分为C1和C2，即客户端和服务端
       C1编译器会对字节码进行简单和可靠的优化，耗时短，以达到更快的编译速度。
       C2进行耗时较长的优化，以及激进优化，但优化的代码执行效率更高。
                C1编译器优化策略主要有方法内联、去虚拟化、冗余消除。
                C2编译器优化策略主要有 标量替换：用标量值代替聚合对象的属性值，栈上分配：对于未逃逸的对象分配对象在栈而不是堆，同步消除：清除同步操作，通常指synchronized
    (2) 如何监测热点代码
           方法调用计数器(会有热点衰减)
           回边计数器：循环体执行次数
           
```

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/JVM/%E7%83%AD%E7%82%B9%E4%BB%A3%E7%A0%81%E6%A3%80%E6%B5%8B_JIT.png" style="zoom:67%;" />

#### 2.3.5 JVM调优

```java
1.常用的调优指令
	(1) jps // 查看jvm进程
	(2) jstat(JVM Statistics Monitoring Tool) // 显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据，没有GUI图形界面，它是运行期定位虚拟机性能问题的首选工具。常用于检测垃圾回收问题以及内存泄漏问题。
	(3) jinfo(Configuration Info for Java) // 查看虚拟机配置参数信息，也可用于调整虚拟机的配置参数。
	(4) jmap(JVM Memory Map) // 作用一方面是获取dump文件（堆转储快照文件，二进制文件），它还可以获取目标Java进程的内存相关信息，包括Java堆各区域的使用情况、堆中对象的统计信息、类加载信息等。
    // 由于jmap将访问堆中的所有对象，为了保证在此过程中不被应用线程干扰，jmap需要借助安全点机制，让所有线程停留在不改变堆中数据的状态。也就是说，由jmap导出的堆快照必定是安全点位置的。这可能导致基于该堆快照的分析结果存在偏差。举个例子，假设在编译生成的机器码中，某些对象的生命周期在两个安全点之间，那么:live选项将无法探知到这些对象
	(5) jhat(JVM Heap Analysis Tool) // jhat命令与jmap命令搭配使用，用于分析jmap生成的heap dump文件（堆转储快照）。jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，用户可以在浏览器中查看分析结果
	(6) jstack(JVM Stack Trace) // 用于生成虚拟机指定进程当前时刻的线程快照（虚拟机堆栈跟踪）。线程快照就是当前虚拟机内指定进程的每一条线程正在执行的方法堆栈的集合。
    // 生成线程快照的作用：可用于定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等问题。这些都是导致线程长时间停顿的常见原因。当线程出现停顿时，就可以用jstack显示各个线程调用的堆栈情况。
    
2.为什么要调优
● 防止出现OOM
● 解决OOM
● 减少Full GC出现的频率
    
体会1：使用数据说明问题，使用知识分析问题，使用工具处理问题。
体会2：无监控、不调优！

3.监控的具体方法：
    1) 堆栈：线程快照、堆dump快照
    2) GC日志
    2) 运行日志(实时监测工具)
    
4.调优步骤：// c
    监控：GC频繁、OOM、响应时间长、cpu负载高
    分析：打印GC日志、dump堆文件、栈信息、
    调优：
    	1) 适当增加内存，根据业务选择垃圾回收器
    	2) 优化代码
    	3) 使用中间件？
5.调优具体策略：
    (1) 增大新生代内存，让更多对象在新生代消化掉。 // 默认和老年代为1：2，调整比例
```



```java
// 遗留的问题
动态连接是个什么玩意？
    栈中会有一个指向运行时常量池该方法的直接引用，以支持动态连接
System.gc()为什么不能立即生效，fullgc都有哪些
CMS、G1

```

### 2.4 并发

#### 2.4.1 Java内存模型

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/%E5%B9%B6%E5%8F%91/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%9B%BE.png" style="zoom:67%;" />

**CPU架构**

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/%E5%B9%B6%E5%8F%91/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/CPU%E6%9E%B6%E6%9E%84.png" style="zoom:67%;" />

**CPU内存模型**

![](https://raw.githubusercontent.com/Sadiyayan/review/master/%E5%B9%B6%E5%8F%91/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/CPU%E7%AE%80%E5%8C%96%E6%9E%B6%E6%9E%84.png)

**Java内存模型**

![](https://raw.githubusercontent.com/Sadiyayan/review/master/%E5%B9%B6%E5%8F%91/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/CPU%E8%BD%AC%E5%8C%96-JMM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.png)

```java
1.顺序一致性模型(和JMM是两个东西)
    顺序一致性内存模型中的每个操作必须立即对任意线程可见。
    但是，在 JMM 中就没有这个保证。未同步程序在 JMM 中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致

2.Java内存模型
    JMM 是一个语言级的内存模型，由JVM规范定义，不像C或C++一样，JMM屏蔽了各种硬件和操作系统的内存访问差异，JMM主要目的是定义程序中各种变量（共享变量，不包括局部变量和方法参数）的访问规则，即关注JVM中把变量值从工作内存中存储到主内存和从主内存中取出变量值到工作内存；处理器内存模型是硬件级的内存模型（在特定协议下，对特定内存或者高速缓存进行读写访问的过程抽象）；顺序一致性内存模型是一个理论参考模型。
    JMM和JVM运行时数据区对应的堆、栈、方法区是两个维度的划分，二者没有任何关系；如果对应起来，从主内存和工作内存的定义来看，主内存主要对应堆中的对象实例数据部分，工作内存对应栈中部分区域；硬件角度看，主内存对应物理硬件的内存，工作内存主要是寄存器和高速缓存。
3.为什么需要多线程
	(1) 并发三要素 ----- 原子性、可见性、有序性
        CPU 增加了缓存，以均衡与内存的速度差异；// 导致 可见性问题 
        操作系统增加了进程、线程以分时复用 CPU，进而均衡CPU与I/O 设备的速度差异；// 分时复用CPU导致原子问题 
        编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。// 导致有序性问题
    (2)重排序的种类
        1) 编译器优化的重排序。对于没有先后依赖关系的语句，编译器可以重新调整语句的执行顺序。 
        2) 指令级并行的重排序。在指令级别，让没有依赖关系的多条指令并行。硬件架构上讲，指CPU允许将多条指令不按程序规定的顺序分开发送给各个相应的电路单元进行处理 // 只有不存在数据依赖的指令才会进行指令重排序
        3) 内存系统的重排序。CPU有自己的缓存(针对storebuffer和loadbuffer)，指令的执行顺序和写入主内存的顺序不完全一致

    	// 内存屏障：一组处理器指令，用于实现对内存操作的顺序限制
	    上述的 1) 属于编译器重排序，2) 和 3) 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。// 对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时,插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序
        // 我的理解：x86架构下只有storeload存在，底层会有lock指令，一是强制storebuffer数据刷回主存，解决内存重排序的问题，也就是可见性问题；二是解决指令重排的问题，也就是有序性问题(lock指令把修改同步到内存的时，意味着所有之前的操作已经完成了，这就是指令重排无法越过屏障的效果)。

4.如何解决重排序
	(1) 单线程的重排序 
		as-if-serial 语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守 as-if-serial 语义。

	(2) 多线程的重排序
		happen before 规则
        (1) 在一个线程内，在程序前面的操作先行发生于后面的操作 // 单一线程规则
        (2) 一个 unlock 操作先行发生于后面对同一个锁的 lock 操作 // 管程锁定规则
        (3) 对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作 //volatile 变量规则
        (4) Thread 对象的 start() 方法调用先行发生于此线程的每一个动作 // 线程启动规则
        (5) Thread 对象的结束先行发生于 join() 方法返回 // 线程加入规则
        (6) 对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。//线程中断规则
        (7) 一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始 // 对象终结规则
        (8) 如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C // 传递性

5.线程安全
    (1) 定义：多个线程同时访问一个共享数据，如果无需考虑同步，都可以获得正确结果，那这个数据就是线程安全的数据。
    (2) 分类：线程安全并不是非真即假，按照共享数据可以分为以下五类
		1) 不可变：不可变的数据一定是线程安全的，如 1) final修饰的基本数据类型 2) 对象：String、部分Number子类(Integer、Double)
         2) 绝对线程安全：无需任何同步就能实现线程安全
         3) 相对线程安全：对象的单次操作是安全的，但是一些特定顺序的连续调用不是安全的，需要在调用时附加同步操作(如：Vector同时get、remove一系列操作会产生数组下标越界异常)
         4) 线程兼容：对象本身不是安全的，在调用端附加额外同步操作，实现线程安全(太多这样的例子了)
         5) 线程对立 // 不记了
	(3) 实现线程安全的方法：
         1) 互斥同步：Synchronized、Reentrantlock // 悲观锁
         2) 非阻塞同步：CAS // 乐观锁
         3) 无同步方法：可重入代码、threadlocal // 这里还不懂，同步和线程安全并没有必然联系
//CAS
    // unsafe类可以分配直接内存
    jdk底层实现的原子性要求只能在一个处理器上完成，有对应的命令，不能在多个处理器上完成CAS
    CAS操作对应Unsafe类中的方法，在JVM中JIT会将该方法编译成一条指令，x86架构下是cmpxchg指令。JDK9之前只有启动类加载器加载的class可以访问Unsafe类中的方法，因此只有Java类库才可以使用CAS，用户程序想要访问就需要通过反射；JDK9之后VarHandle类中开放了用户程序使用的CAS操作。
    CAS有ABA问题，JUC提供了一个带有标记的原子引用类AtomicStampedReference，通过控制变量值的版本保证CAS的正确性。 // AtomicStampedReference使用没看明白呢
    AtomicInteger底层实现? CAS+volatile
//ThreadLocal
    每个线程的Thread对象中有一个ThreadLoaclMap对象，该对象存储了以ThreadLocal为键，本地线程变量为值的K-V对，使用ThreadLocal就可以找到本地线程的变量



    // hsids可以把java代码的汇编打印出来

```

##### 2.4.1.1 Synchronized

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/%E5%B9%B6%E5%8F%91/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/%E7%AE%A1%E7%A8%8B.png" style="zoom: 50%;" />

```JAVA
// 可见性
JMM中关于synchronized有如下规定，线程加锁时，必须清空工作内存中共享变量的值，从而使用共享变量时需要从主内存重新读取；线程在解锁时，需要把工作内存中最新的共享变量的值写入到主存，以此来保证共享变量的可见性
// 原子性，只有一个线程在执行。有序性：隔离了其他线程，肯定是有序的啊
    
(1) 弊端：如要阻塞或则唤醒一条线程，需要操作系统帮忙，会从用户态切换到内核态，会耗费很多时间，除此之外还要维护锁计数器等
(2) 管程：
     1)   管程是一种在信号量机制上进行改进的并发编程模型，解决了信号量在临界区的 PV 操作上配对的麻烦，把配对的 PV 操作集中在一起而形成的并发编程方法理论，极大降低了使用和理解成本。
    管程由四部分组成：
    1管程内部的共享变量。
    2管程内部的条件变量。
    3管程内部并行执行的进程。
    4对于局部与管程内部的共享数据设置初始值的语句。
    由此可见，管程就是一个对象监视器。任何线程想要访问该资源（共享变量），就要排队进入监控范围。进入之后，接受检查，不符合条件，则要继续等待，直到被通知，然后继续进入监视器。需要注意的事，信号量和管程两者是等价的，信号量可以实现管程，管程也可以实现信号量，只是两者的表现形式不同而已，管程对开发者更加友好。
    两者的区别如下：

    管程为了解决信号量在临界区的 PV 操作上的配对的麻烦，把配对的 PV 操作集中在一起，并且加入了条件变量的概念，使得在多条件下线程间的同步实现变得更加简单。
    
    2) 管程是一个抽象的概念模型，其封装了一套对共享资源访问的模型，目的是通过一个模型来管理共享资源的访问过程，让可能存在多个进程或线程同时访问一个共享资源时能达到"互斥"和"同步"的效果,管程实现管程模型必须达到下面两点要求。管程（Monitor）是一种和信号量（Sophomore）等价的同步机制，是synchronized和wait()/notify()等线程同步和线程间协作工具的基石：当我们在使用这些工具时，其实是它在背后提供了支持
    管程使用锁（lock）确保了在任何情况下管程中只有一个活跃的线程，即确保线程互斥访问临界区，管程使用条件变量（Condition Variable）提供的等待队列（Waiting Set）实现线程间协作，当线程暂时不能获得所需资源时，进入队列等待，当线程可以获得所需资源时，从等待队列中唤醒

    1、管程中的共享变量对于外部都是不可见的，只能通过管程才能访问对应的共享资源。

    2、管程是互斥的，某个时刻只能允许一个进程或线程访问共享资源。

    3、管程中需要有线程等待队列和相应等待和唤醒操作。

    4、必须有一种办法使进程无法继续运行时被阻塞。
    通过上面的管程我们再来看JAVA里面的管程Monitor了，JAVA是通过sychronyzed关键字，和wait()、notify、notifyAll() 方法实现了整个管程模型，与上面标准的管程模型不同的是，JAVA的Monitor属于一种简单的管程模型，因为它并没有使用多个条件变量的队列，不管是竞争锁产生的阻塞，还是拿到锁因为某个条件不合格导致的阻塞，统一都放入一个队列了
    Java中的每个对象都与一个monitor关联，线程可以lock或unlock monitor。每个对象除具有关联的monitor外，还具有关联的等待集。等待集是一个线程集合。Object.wait, Object.notify, and Object.notifyAll.
	首次创建对象时，其等待集为空。将线程添加到等待集中或从等待集中删除线程的基本操作是原子的。等待集仅通过Object.wait, Object.notify和Object.notifyAll方法操作。每个对象还有一个锁计数器，当线程持有该对象的管程后，计数器就会加一
(3) 实现：
    1) JVM 使用了 ACC_SYNCHRONIZED 访问标志来区分一个方法是否是同步方法
    2) Synchronized 在修饰同步代码块时，是由 monitorenter 和 monitorexit 指令来实现同步的
    二者都是通过判断是否获得对象的monitor来判断是否获得该代码区域的执行权
(4) 锁升级过程
    // 锁膨胀的过程：无锁(没有线程)->偏向锁(1个线程)->轻量级锁(同时有第二个的线程竞争锁)->重量级锁(同时有三个及以上的线程竞争锁)
    1) 无锁状态
    2) 偏向锁
    	Ⅰ JVM设置不可偏向：直接轻量级锁
    	Ⅱ JVM设置可偏向：
    		此时markword中锁状态为0,即无锁状态,线程通过CAS在Markword记录本线程ID,并将偏向锁位设置为1，如果失败说明此时至少两个线程，获得偏向锁的线程肯定还需要锁不能放，所以需要到安全点撤销偏向锁再升级为轻量级锁。
    		如果有一个线程1CAS成功设置markword中的id了(偏向锁不会主动释放锁，需要有线程来竞争，也就是说markword有id后就会一直有id，线程直接检查markword中的id是否和自己一样就好了)，此时又有一个线程检查markword中的id和自己一样就直接继续执行同步块，无需CAS加锁解锁；如果不一样需要看线程1是否存活，没有存活，锁对象就会被重置为无锁状态，重新偏向新的线程；如果线程1存活，首先要等到全局安全点暂停该线程 ，即STW，然后查找线程1的栈帧信息，如果线程1不需要这个对象了,锁对象被重置为无锁状态，重新偏向新的线程；如果还需要持有这个锁的对象，撤销偏向锁并升级为轻量级锁，然后恢复线程1从安全点继续运行，产生竞争的线程则通过CAS不断获取轻量级锁，失败则自旋，自旋达到一定次数后(默认是十次，也可以采取自适应自旋锁)或者在自旋过程中又来了一个线程来竞争轻量级锁，原锁就会膨胀为重量级锁，也就是管程对象。
    	    // 如果一个对象计算过一致性hashcode就无法进入偏向锁了，因为偏向锁无法存储一致性hashcode；如果对象正处于偏向锁状态，又需要计算一致性hashcode，偏向状态会立即被撤销，锁膨胀为重量级锁
    3) 轻量级锁
    	轻量级锁的获取过程：把锁对象的对象头MarkWord信息复制一份到线程1的栈帧中创建的叫锁记录(lock record)的地方，复制到锁记录的markword信息也称为DisplacedMarkWord，然后使用CAS把对象头中的内容替换为线程1存储的锁记录。也就是说在竞争时，所有线程都会复制对象头的markword信息到自己的栈中锁记录里，只不过在CAS过程中会替换引用失败而已。// 如果出现两条以上的线程同时竞争，轻量级锁不再有效，需膨胀为重量级锁。
    	轻量级锁解锁过程：同样用CAS操作把DisplacedMarkWord的内容替换到对象头中的markword，如果替换失败说明发生过竞争(我的理解：此时对象是引用地址，假如竞争过，各线程栈帧的lock record中都有原markword信息，所以不需要替换回去，将对象的markword改为别的线程的DisplacedMarkWord引用就好了)，需要在释放锁的同时唤醒被挂起的线程；如果替换成功则同步顺利完成。
    4) 重量级锁

```

##### 2.4.1.2 volatile

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/%E5%B9%B6%E5%8F%91/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/JMM%E5%AF%B9volatile%E9%87%8D%E6%8E%92%E5%BA%8F%E7%9A%84%E8%A7%84%E5%88%99.png" style="zoom:67%;" />

```java
volatile:
	volatile可以保证解决可见性和有序性问题，但是不能保证原子性，所以不能保证是并发安全的!!!
		(1)volatile关键字可以确保直接从主内存读取给定变量，并在更新时始终写回主内存。 
    	(2) volatile禁止指令重排序优化(volatile变量的写入会和非volatile变量的读取或写入重排序)
    	// 以上两条语义底层实现通过汇编的lock指令(lock会锁住主存)，1) 将当前处理器缓存行的数据立即写回主内存 2) 借助MESI协议写回操作会引起其他CPU相同缓存行无效化
         (3) 64位写入的原子性，如long、double
		(4) 不能保证原子性，对于i++这样的自增操作，用volatile修饰可以保证线程的工作内存的值是从主内存读到的，但是自增操作在处理器上是多步骤指令的，有可能在执行这些指令的时候，还有其他线程已经完成了自增操作，这条自增并不是原子性的完成，最后结果肯定是更小一些。
    
    为了保证内存可见性，java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。
    JMM针对编译器制定的规则
        当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。
        当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。
        当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。
    
	JMM针对编译器上述规则的内存屏障插入策略：
        在每个volatile写操作的前面插入一个StoreStore屏障。
        在每个volatile写操作的后面插入一个StoreLoad屏障。
        在每个volatile读操作的后面插入一个LoadLoad屏障。
        在每个volatile读操作的后面插入一个LoadStore屏障。
    	// 这四种屏障都是JVM层面的功能，只不过JVM底层简化了内存屏障硬件指令，采取lock代替。
    x86处理器仅会对写-读操作做重排序，所以只需要StoreLoad屏障，其他屏障均会被优化掉。而StoreLoad屏障底层是lock指令为前缀的'一段汇编代码'，lock指令并不是真正的内存屏障，只是提供了内存屏障的功能：1) 将当前处理器缓存行的数据立即写回主内存 2) 借助MESI协议写回操作会引起其他CPU相同缓存行无效化 3) lock指令把修改同步到内存的时，意味着所有之前的操作已经完成了，这就是指令重排无法越过屏障的效果，解决了指令重排的问题
```

##### 2.4.1.3 final 

```

```



#### 2.4.2 Java线程

```java
1.线程的生命周期和状态
    共六种
    (1) new
    (2) runnable 包括操作系统的running和ready
    (3)	waiting // Object.wait()、Thread.join()、LockSupport.park()
    (4) timed waiting // wait(time)、join(time)、LockSupport:parkNanos/parkUntil、Thread.sleep()
    (5) blocked // synchronize
    (6) terminated
	// await() signal() signalAll()
    // wait() notify() notifyAll()
    // 只有LockSupport的park方法不会抛出中断异常，所以在响应中断时可以继续执行剩余的代码；park和unpark方法 阻塞是采用许可证的方式，只有一个许可证，默认是被占用的，所以先执行park方法线程没有许可证就会被阻塞；如果先执行unpark会释放许可证，再park线程就会得到许可证，不会被阻塞，也就是说二者不像wait/notify 没有先后顺序问题。
2.创建线程的方式
    (1) 实现Runnable接口重写run方法(无返回值)，然后传入Thread的构造方法，调用start()
    (2) 实现Callable接口重写call方法(带返回值)，然后传入FutureTask的构造方法，最后将FutureTask对象传入Thread的构造方法,调用start()
    (3) 继承Thread类重写run方法，构造该对象调用start()
    选择：实现接口会更好一些，原因:
		1) Java 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口；
		2) 类可能只要求可执行就行，继承整个 Thread 类开销过大。

3.线程中断
     // 被wait、join、sleep阻塞的方法在调用interrupt()方法时会产生中断异常而退出，使得等待在这些方法上的方法可以继续执行。原理就是线程被挂起仍需要执行中断标记操作就会抛出异常，提前结束。
	通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。
    interrupt()和isinterrupt()方法是实例方法，interrupted()方法是静态方法，底层调用isinterrupt(true)方法，可以重置中断标记的状态
            
        
4.线程中的join()方法解析
public static void main(String[] args){
    //启动一个子线程
    Thread threadA = new Thread(new Runnable() {
        @Override
        public void run() {
        }
    });
    threadA.start();
    try {
        threadA.join();    //调用join()
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
}
public final void join() throws InterruptedException {
    join(0);
}
// 主线程中调用线程threadA的join方法，主线程会阻塞在threadA的队列上，也就是阻塞在下面的wait方法上，而当threadA线程执行完之后，会自动调用nutifyAll方法唤醒阻塞在threadA上的主线程，实现join的功能。
public final synchronized void join(long millis) throws InterruptedException {
    long base = System.currentTimeMillis();  //获取当前时间
    long now = 0;
    if (millis == 0) {    //这个分支是无限期等待直到b线程结束
        while (isAlive()) {
            wait(0);
        }
    } 
    // 代码略
}   

```



#### 2.4.3 Java中的锁

##### 2.4.3.1 LockSupport

```java
// 只有LockSupport的park方法不会抛出中断异常，所以在响应中断时可以继续执行剩余的代码；park和unpark方法 阻塞是采用许可证的方式，只有一个许可证，默认是被占用的，所以先执行park方法线程没有许可证就会被阻塞；如果先执行unpark会释放许可证，再park线程就会得到许可证，不会被阻塞，也就是说二者不像wait/notify 没有先后顺序问题
主要有park()和unpark()方法 ，LockSupport.park()底层是调用的Unsafe的native方法
    调用Unpark()方法被阻塞的线程结束阻塞    
    其他某个线程将当前线程作为目标调用 unpark。
    其他某个线程中断当前线程。
```

##### 2.4.3.2 AQS

```java
1.定义：
    AQS框架借助于两个类：Unsafe(提供CAS操作)和LockSupport(提供park/unpark操作)
	AQS是一个用来构建锁和同步器的框架（所谓同步，是指线程之间的通信、协作）
	AQS特性：阻塞等待队列、共享/独占、公平/非公平、可重入、允许中断

2.核心思想
	AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。
	CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。
	自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可！！！！！，至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)，AQS已经在上层已经帮我们实现好了。
	重写方法很简单，无非是对于共享资源state的获取和释放//state 由于是多线程共享变量，所以必须定义成 volatile，以保证 state 的可见性, 同时虽然 volatile 能保证可见性，但不能保证原子性，所以 AQS 提供了对 state 的原子操作方法，保证了线程安全。
    
3.需要重写的方法 / AQS模板方法中调用的方法
    isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。
    tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。
    tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。
    tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
    tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。
    
4.数据结构
    继承自AOS，AOS中只定义了当前占用共享资源线程的方法
    内部类：
    	Node
    	ConditionObject
    核心方法：
    	accquire() // 调用重写的
    	release()
	队列：
    	同步队列：双向链表，用于获取同步状态的队列
    	条件队列：单向链表，具体实现在ConditionObject中，包括await()和signal()方法
    		await()方法：只有获取锁的线程才会调用到该方法
    			1) 构造该节点线程为一个新的节点加入到条件队列中 
    			2) 释放同步状态，唤醒后继节点
    			3) 阻塞条件队列中的线程
    		signal()方法：只有获取锁的线程才会调用到该方法(唤醒别的线程需要本线程做些操作，而做些操作一定获取了锁)
    			1) 将条件队列的首节点移入同步队列并使用LockSupport唤醒该线程继续执行await()方法剩余部分
    			2) 剩余部分会调用AQS中的acquiredQueue()方法
```

##### 2.4.3.3 Reentrantlock

**Synchronized和ReenTrantLock的不同**

1. 实现方面：synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 API
2. 功能方面：ReenTrantLock功能更多：1) 可响应中断 2) 可以实现公平锁 3）多个等待条件

二者都是可重入锁，性能不是选择标准，Synchronized做了优化：偏向锁、轻量级锁、重量级锁

```java
// Reentrantlock中内部类Sync继承了AQS，FairSync 和 NonfairSync 是 ReentrantLock 实现的内部类，都继承了Sync内部类，分别指公平和非公平模式，FairSync，NonfairSync只是重写tryAcquire()方法，即获取独占锁的方式

// 公平锁和非公平锁区别：公平锁中在可以获取共享资源的情况下，只要还有等待时间更长的线程，该线程就会添加到sync queue中的尾部，而不会先尝试获取资源。这也是和Nonfair最大的区别，Nonfair每一次都会尝试去获取资源，如果此时该资源恰好被释放，则会被当前线程获取，这就造成了不公平的现象，当获取不成功，再加入队列尾部。

// lock 方法主要有两步 1) 使用 CAS 来获取 state 资源，如果成功设置 1，代表 state 资源获取锁成功，此时记录下当前占用 state 的线程 setExclusiveOwnerThread(Thread.currentThread()); 2) 如果 CAS 设置 state 为 1失败（代表获取锁失败），则执行 acquire(1) 方法，这个方法是 AQS 提供的方法
public void lock() {
    // 具体实现在公平和非公平锁内
    sync.acquire(1);
}
// AQS中的模板方法
public final void acquire(int arg) {
    // 如果tryAcquire 锁失败则创建节点并入队
    if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        // 如果是因为中断唤醒的线程，获取锁后需要补一下中断
        selfInterrupt();
}
// 先分析非公平锁
// class NonfairSync 非公平锁中重写的tryAcquire
protected final boolean tryAcquire(int acquires) {
    return nonfairTryAcquire(acquires);
}
// nonfairTryAcquire在Sync中定义
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    // 此时state还没有被获取到
    if (c == 0) {
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    // 同一线程可重入
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}

// 如果tryAcquire失败，将线程加入到CLH队列中
private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);
    Node pred = tail;
    // 如果尾结点不为空，则用 CAS 将获取锁失败的线程入队
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    // 如果尾结点为空 或者CAS加入尾节点失败，执行 enq 方法
    enq(node);
    return node;
}

private Node enq(Node node){
    // 无线循环，直到等待线程的节点加入到CLH队列
    for (;;) {
        Node t = tail;
        if (t == null) {
            // 尾结点为空，说明 FIFO 队列未初始化，所以先初始化其头结点；CAS创建头结点简单调用了 new Node() 方法，并不像其他节点那样记录 thread，这里 head 结点为虚结点，它只代表当前有线程占用了 state，至于占用 state 的是哪个线程，其实是调用了上文的 setExclusiveOwnerThread(current) ，即记录在 exclusiveOwnerThread 属性里(在AOS属性中，AOS中只有这个属性以及对应方法)。
            // 默认构造下节点的线程为null，waitstatus为0，后边accquireQueue方法中如果head节点还为零，并且后继结点获取锁失败，就会设置其waitstatus为1
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            // 尾结点不为空，则将等待线程入队
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
}

// 不过可能有一个问题，如果当前锁是独占锁，如果锁一直被被 T1 占有， T2，T3 一直自旋没太大意义，反而会占用 CPU，影响性能，所以更合适的方式是它们自旋一两次竞争不到锁后识趣地阻塞以等待前置节点释放锁后再来唤醒它。另外如果锁在自旋过程中被中断了，或者自旋超时了，应该处于「取消」状态。所以有如下判断是否阻塞方法

// 执行完 addWaiter 后，线程入队成功，最后一个最关键的方法 acquireQueued，问题在于线程节点入队后应该自旋多久，什么时候阻塞
	static final Node SHARED = new Node();//标识等待节点处于共享模式
    static final Node EXCLUSIVE = null;//标识等待节点处于独占模式
    static final int CANCELLED = 1; //由于超时或中断，节点已被取消
    static final int SIGNAL = -1;  // 节点阻塞（park）必须在其前驱结点为 SIGNAL 的状态下才能进行，如果结点为 SIGNAL,则其释放锁或取消后，可以通过 unpark 唤醒下一个节点，
    static final int CONDITION = -2;//表示线程在等待条件变量（先获取锁，加入到条件等待队列，然后释放锁，等待条件变量满足条件；只有重新获取锁之后才能返回）
    static final int PROPAGATE = -3;//表示后续结点会传播唤醒的操作，共享模式下起作用
    //等待状态：对于condition节点，初始化为CONDITION；其它情况，默认为0，通过CAS操作原子更新
    volatile int waitStatus;


final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        // 自旋
        for (;;) {
            final Node p = node.predecessor();
            // 如果前一个节点是 head，则尝试自旋获取锁
            if (p == head && tryAcquire(arg)) {
                //  将 head 结点指向当前节点，原 head 结点出队
                setHead(node); // head = node;node.thread = null;node.prev = null;
                p.next = null; // 让原head节点引用和被引用为空，help GC
                failed = false;
                return interrupted;
            }
            // 如果前一个节点不是 head 或者竞争锁失败，则进入阻塞状态
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                // 根据第二个阻塞方法的返回值，如果线程阻塞后是被中断唤醒的，就会到这里设置interrupted为true
                interrupted = true;
        }
    } finally {
        if (failed)
            // 如果线程自旋中因为异常等原因获取锁最终失败，则调用此方法
            cancelAcquire(node);
    }
}

private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL)
        // 前节点状态为SIGNAL则应该阻塞当前节点的线程
        return true;
    if (ws > 0) {
        // 前节点为取消状态(1是CANCELLED)
        do {
            // 找到第一个不为CANCELLED的节点
            node.prev = pred = pred.prev;
        } while (pred.waitStatus > 0);
        pred.next = node;
    } else {
        // waitStatus must be 0 or PROPAGATE,并设置当前节点为SIGNAL！！！，等到下次来的时候就会进入第一个if条件，从而去执行阻塞方法
        pred.compareAndSetWaitStatus(ws, Node.SIGNAL);
    }
    return false;
}

// 阻塞线程
private final boolean parkAndCheckInterrupt() {
    LockSupport.park(this);
    // 返回线程是否中断过，并且清除中断状态（在获得锁后会补一次中断）
    return Thread.interrupted();
}

// 取消节点
private void cancelAcquire(Node node){
    // 如果节点为空，直接返回
    if (node == null)  return;
    // 由于线程要被取消了，所以将 thread 线程清掉
    node.thread = null;
    // 下面这步表示将 node 的 pre 指向之前第一个非取消状态的结点（即跳过所有取消状态的结点）,waitStatus > 0 表示当前结点状态为取消状态
    Node pred = node.prev;
    while (pred.waitStatus > 0)
        node.prev = pred = pred.prev;
    // 获取经过过滤后的 pre 的 next 结点，这一步主要用在后面的 CAS 设置 pre 的 next 节点上
    Node predNext = pred.next;
    // 将当前结点设置为取消状态
    node.waitStatus = Node.CANCELLED;
    // 如果当前取消结点为尾结点，使用 CAS 则将尾结点设置为其前驱节点，如果设置成功，则尾结点的 next 指针设置为空
    if (node == tail && compareAndSetTail(node, pred)) {
        compareAndSetNext(pred, predNext, null);
    } else {
    // 这一步看得有点绕，我们想想，如果当前节点取消了，那是不是要把当前节点的前驱节点指向当前节点的后继节点，但是我们之前也说了，要唤醒或阻塞结点，须在其前驱节点的状态为 SIGNAL 的条件才能操作，所以在设置 pre 的 next 节点时要保证 pre 结点的状态为 SIGNAL，想通了这一点相信你不难理解以下代码。
        int ws;
        if (pred != head &&
            ((ws = pred.waitStatus) == Node.SIGNAL ||
             (ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &&
            pred.thread != null) {
            Node next = node.next;
            if (next != null && next.waitStatus <= 0)
                compareAndSetNext(pred, predNext, next);
        } else {
        // 如果 pre 为 head，或者  pre 的状态设置 SIGNAL 失败，则直接唤醒后继结点去竞争锁，之前我们说过， SIGNAL 的结点取消（或释放锁）后可以唤醒后继结点
            unparkSuccessor(node);
        }
        node.next = node; // help GC
}
    
// java.util.concurrent.locks.AbstractQueuedSynchronizer  
// 释放锁
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        // head为null或者头节点无后续节点的时候不会唤醒后继节点
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}
// java.util.concurrent.locks.ReentrantLock.Sync
protected final boolean tryRelease(int releases) {
    int c = getState() - releases;
    // 只有持有锁的线程才能释放锁，所以如果当前锁不是持有锁的线程，则抛异常
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    // 说明线程持有的锁全部释放了，需要释放 exclusiveOwnerThread 的持有线程
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}
private void unparkSuccessor(Node node) {
    if (ws < 0)  compareAndSetWaitStatus(node, ws, 0);
    // 以下操作为获取队列第一个非取消状态的结点，并将其唤醒
    Node s = node.next;
    // s 状态为非空，或者其为取消状态，说明 s 是无效节点，此时需要执行 if 里的逻辑
    if (s == null || s.waitStatus > 0) {
        s = null;
        // 以下操作为从尾向前获取最后一个非取消状态的结点；因为节点入队并不是原子操作，对应addWaiter中的方法，线程自旋时时是先执行 node.pre = pred, 然后再执行 pred.next = node，如果 unparkSuccessor 刚好在这两者之间执行，此时是找不到 head 的后继节点的，所以要从后往前找
        for (Node t = tail; t != null && t != node; t = t.prev)
            if (t.waitStatus <= 0)
                s = t;
    }
    if (s != null)
        LockSupport.unpark(s.thread);
}
```

##### 2.4.3.4 ReentrantReadWriteLock

```java
// ReentrantReadWriteLock 
	维护一对锁：读锁和写锁
    读写锁在读多写少的场景，能发挥出优势
    读写锁可以分为读优先锁和写优先锁
    读优先锁：线程A持有读锁，线程B获取写锁会被阻塞，在此过程中，后续来的读线程C仍然可以获取读锁，直到A和C都释放读锁，B才可以获取写锁。
    写优先锁：线程A持有读锁，线程B获取写锁会被阻塞，在此过程中，后续来的读线程C不可以获取读锁，于是C会被阻塞，这样只要A释放读锁，B就可以成功获取写锁。// 读优先锁会饿死写线程，写优先锁会饿死读线程，于是用队列实现公平读写锁。
    
1.优势：
    (1) 并发性比一般排他锁有提升
    (2) 写操作对读操作可见
    (3) 简化读写交互的场景
        
2.在读锁的获取同步状态中，如果当前线程处于写锁是可以获取读锁的，所以有了锁降级的事情。
    锁降级：当前线程拥有写锁，然后获取读锁，再释放写锁。(拥有写锁再释放写锁再获取读锁，这种分段过程不算锁降级)
    锁降级的必要性：
        1) 保证当前线程修改的数据可以被读到，假如释放写锁后，另一写线程T修改数据，那么对于该数据原来线程可能会读到不是自己修改的数据，会有可见性问题
        2) 为了提高程序执行性能，可能存在一个事务线程不希望自己的操作被别的线程中断，而这个事务操作可能分成多部分操作更新不同的数据（或表）甚至非常耗时。如果长时间用写锁独占，显然对于某些高响应的应用是不允许的，所以在完成部分写操作后，退而使用读锁降级，来允许响应其他进程的读操作。只有当全部事务完成后才真正释放锁

// 源码及如何使用并没有详细分析
```

#### 2.4.4 并发工具类

```java
1.CountDownLatch
	其底层是由AQS提供支持，所以其数据结构可以参考AQS的数据结构，而AQS的数据结构核心就是两个虚拟队列: 同步队列sync queue 和条件队列condition queue，不同的条件会有不同的条件队列。
     CountDownLatch典型的用法是将一个程序分为n个互相独立的可解决任务，并创建值为n的CountDownLatch。当每一个任务完成时，都会在这个锁存器上调用countDown，等待问题被解决的任务调用这个锁存器的await，将他们自己拦住，直至锁存器计数结束。

/**
 * 使用CountDownLatch 代替wait notify 好处是通讯方式简单，不涉及锁定  Count 值为0时当前线程继续执行，
 */
public class T3 {

   volatile List list = new ArrayList();

    public void add(int i){
        list.add(i);
    }

    public int getSize(){
        return list.size();
    }


    public static void main(String[] args) {
        T3 t = new T3();
        CountDownLatch countDownLatch = new CountDownLatch(1);

        new Thread(() -> {
            System.out.println("t2 start");
           if(t.getSize() != 5){
               try {
                   countDownLatch.await();
                   System.out.println("t2 end");
               } catch (InterruptedException e) {
                   e.printStackTrace();
               }
           }
        },"t2").start();

        new Thread(()->{
            System.out.println("t1 start");
           for (int i = 0;i<9;i++){
               t.add(i);
               System.out.println("add"+ i);
               if(t.getSize() == 5){
                   System.out.println("countdown is open");
                   countDownLatch.countDown();
               }
           }
            System.out.println("t1 end");
        },"t1").start();
    }

}

2.CyclicBarrier

class MyThread extends Thread {
    private CyclicBarrier cb;
    public MyThread(String name, CyclicBarrier cb) {
        super(name);
        this.cb = cb;
    }
    
    public void run() {
        System.out.println(Thread.currentThread().getName() + " going to await");
        try {
            cb.await();
            System.out.println(Thread.currentThread().getName() + " continue");
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
public class CyclicBarrierDemo {
    public static void main(String[] args) throws InterruptedException, BrokenBarrierException {
        CyclicBarrier cb = new CyclicBarrier(3, new Thread("barrierAction") {
            public void run() {
                System.out.println(Thread.currentThread().getName() + " barrier action");
                
            }
        });
        MyThread t1 = new MyThread("t1", cb);
        MyThread t2 = new MyThread("t2", cb);
        t1.start();
        t2.start();
        System.out.println(Thread.currentThread().getName() + " going to await");
        cb.await();
        System.out.println(Thread.currentThread().getName() + " continue");

    }
}
// 某一可能的结果
t1 going to await
main going to await
t2 going to await
t2 barrier action
t2 continue
t1 continue
main continue
   
----------------------------------------------------
// CountDownLatch和CyclicBarrier的对比
	(1) CountDownLatch减计数，CyclicBarrier加计数。 
	(2) CountDownLatch是一次性的，CyclicBarrier可以重用。
	(3)CountDownLatch和CyclicBarrier都有让多个线程等待同步然后再开始下一步动作的意思，但是CountDownLatch的下一步的动作实施者是主线程，具有不可重复性；而CyclicBarrier的下一步动作实施者还是“其他线程”本身，具有往复多次实施动作的特点。// 就是说CyclicBarrier的每个线程都要调用await()方法，CountDownLatch中只有等待线程调用await()方法，来等待其他事件的结束

```

#### 2.4.5 并发容器和框架

```
currenthashmap
阻塞队列
Fork/Join框架
```

#### 2.4.6 线程池

```

```

### 2.5 设计模式

```java
单例模式
SpringMVC 适配器模式
AQS 模板方法模式
```



## 3.数据库

### 3.1 MySQL

```java
1.mysql使用b+树而不用b树的原因
	1) 根据局部性原理，需要进行磁盘预读，b+树可以做到，同理，范围查询也可以做到（叶子节点之间有双向指针）。
	2) 除叶子节点外，只包含索引没有data，所以一次IO可以索引更大的数据范围，减少需要的IO次数。
	
2.为什么建议InnoDB表必须建主键，并且推荐使用整型并且自增的主键？
	innodb采取聚集索引，即B+树的叶子节点会存放data（某一行的所有数据），而myisam（非聚集索引）叶子节点存放的是某一行数据的地址，对于主键（唯一非空索引）叶子节点存放所有数据，而普通列的索引只存放对应行的主键值，如果表不建主键的话，mysql自动帮我们找一列做主键建索引，如果没有符合的列，那就有mysql自己维护一个新的列作为主键索引。		总的来说，如果不建索引，MySQL后台还是会为我们维护主键，这相当于增大了开销。
	整型：查找时候做比较很快，而且占空间小。
	自增：插入节点时，在某一叶子节点的后边直接加入即可，方便索引排序。而使用uuid这种的话，可能会导致叶子节点分裂，会影响性能。
	
3.最左前缀原则：
	如果使用联合索引多列，言遵从最左前缀法则，指的是查询从索引的最左列开始并且不跳过索引中的项。
	
4.bufferpool
	mysql的bufferopool存有叶子节点的数据值，采用LRU置换。

5.事务相关问题
	1)并发问题
	脏读：读取了其他并发事务未提交的数据
	不可重复读：读取了其他并发事务提交的数据。针对update和delete
	幻读：读取了其他并发事务提交的数据。针对insert
	
	2)四种隔离级别：读未提交，读已提交，可重复读，序列化
	
	//表锁与行锁的区别：锁定粒度，加锁效率，冲突概率，并发性能
	
	3)事务隔离级别的实现方式
		LBCC
		MVCC
	4)锁的种类
		共享锁（读锁）和排他锁（写锁）--可以应用于行和表（二者都可），都是lock的实现，应用于事务（不是）
		意向共享锁和意向排他锁（均是表锁）--针对共享行锁和排他行锁，在获取时，需要首先获取它们的意向锁，用来判断此表是否含有行锁。
		记录锁、间隙锁、临键锁（记录锁+间隙锁）
		
	5)MVCC底层原理
		Ⅰ注：begin不是一个事务的起点，在执行到第一个操纵innodb表的语句时（增删改，读的事务id不一样），事务才算启动并向mysql申请事务id，并严格按照事务的启动顺序分配事务id
		Ⅱmysql数据库表会为数据库表多两列--事务id和回滚指针
		Ⅲ在RC隔离级别下，是每个SELECT都会获取最新的read view；而在RR隔离级别下，则是当事务中的第一个SELECT请求才创建read view。read view由所有未提交事务id数组（数组中最小的为min_id）和已创建事务的最大事务id（max_id）组成，查询时根据版本链（undolog）的顺序读取trx_id和readview中的事务id进行比较从而查询到结果。
		Ⅳ版本链比对规则：
		if(trx_id<min_id)说明是已提交事务，数据可见
		if(trx_id>max_id)说明是未创建事务，数据不可见
		if(min_id<=trx_id<=max_id)两种情况
		  a 如果trx_id在数组中，数据不可见，但如果当前select的事务id和trx_id相同，则可见
		  b 如果trx_id不在数组中，说明是已提交事务生成的，数据可见
		Ⅴ对于delete可以认为是update的特殊情况，也会将数据复制一份，然后在记录的头信息中的delete_flag设置为true，此后查询到此记录时，则会检查标志位，为true
6.//慢查询如何解决
            
```

## 4.计算机基础

### 4.1 操作系统

```java
// java中的协程是什么？
	（1）协程执行效率极高。协程直接操作栈基本没有内核切换的开销，所以上下文的切换非常快，切换开销比线程更小。
（2）协程不需要多线程的锁机制，因为多个协程从属于一个线程，不存在同时写变量冲突，效率比线程高。
（3）一个线程可以有多个协程。
        协程调用跟切换比线程效率高：协程执行效率极高。协程不需要多线程的锁机制，可以不加锁的访问全局变量，所以上下文的切换非常快。
协程占用内存少：执行协程只需要极少的栈内存（大概是4～5KB），而默认情况下，线程栈的大小为1MB。
切换开销更少：协程直接操作栈基本没有内核切换的开销，所以切换开销比线程少
// 网络中的大端小端、网络字节序
// 硬件结构 -- 未总结
// Reactor模式 -- 未总结
// 零拷贝 -- 未总结
// 网络包流程 -- 未总结
// 进程/线程 的同步方式,线程的通信方式
    线程同步方式：互斥锁、信号量、条件变量、读写锁
        
// fork函数
        fork()函数创建一个新进程后，会为这个新进程分配进程空间，将父进程的进程空间中的内容复制到子进程的进程空间中，包括父进程的数据段和堆栈段，并且和父进程共享代码段。这时候，子进程和父进程一模一样，都接受系统的调度。因为两个进程都停留在fork()函数中，最后fork()函数会返回两次，一次在父进程中返回PID，一次在子进程中返回0或者-1，两次返回的值不一样

// 孤儿进程、僵尸进程
孤儿进程：是指一个父进程退出后，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被init进程（进程号为1）所收养，并且由init进程对它们完整状态收集工作。

僵尸进程：是指一个进程使用fork函数创建子进程，如果子进程退出，而父进程并没有调用wait()系统调用取得子进程的终止状态，那么子进程的进程描述符仍然保存在系统中，占用系统资源，这种进程称为僵尸进程。
        防止办法：一般，为了防止产生僵尸进程，在fork子进程之后我们都要及时使用wait系统调用；同时，当子进程退出的时候，内核都会给父进程一个SIGCHLD信号，所以我们可以建立一个捕获SIGCHLD信号的信号处理函数，在函数体中调用wait（或waitpid），就可以清理退出的子进程以达到防止僵尸进程的目的。
        wait是父进程回收子进程PCB资源的一个系统调用。进程一旦调用了wait函数，就立即阻塞自己本身，然后由wait函数自动分析当前进程的某个子进程是否已经退出，当找到一个已经变成僵尸的子进程，wait就会收集这个子进程的信息，并把它彻底销毁后返回；如果没有找到这样一个子进程，wait就会一直阻塞，直到有一个出现为止
        
//单核下多线程是否需要加锁
    原因：因为线程锁通常用来实现线程的同步和通信。在单核机器上的多线程程序，仍然存在线程同步的问题。因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。如果这两个线程共享某些数据，不使用线程锁的前提下，可能会导致共享数据修改引起冲突
```



#### 4.1.1 硬件结构

用户态切换到内核态的事件：系统调用、异常、硬件中断

#### 4.1.2 内存

```java
1.基本概念
   (1) 虚拟内存:将硬盘的一部分作为内存来使用，是真实存在的
   (2) 虚拟地址空间：并不是真实存在，根据CPU的寻址虚拟出来的一个范围，程序在启动后会假想自己占据全部的虚拟地址空间，但实际只会占据一部分，还有一部分在虚拟内存中也就是硬盘中，当CPU通过MMU找不到物理地址的页时，会产生缺页异常，进入内核态(还是用户态？)，去虚拟内存中找页载入到用户空间中。
	程序所使用的内存地址叫虚拟内存地址(Virtual Memory Address)
	存在硬件里的地址叫物理内存地址(Physical Memory Address)
   (3) 虚拟内存分布(由低地址到高地址)：代码区、初始化数据、未初始化数据、堆区、文件映射区、栈区、内核空间
// CPU封装了内存管理单元(MMU),用来完成地址变换和TLB的访问
// 进程在用户态时只能访问用户空间的内存，只有进入内核态时才可以访问内核空间的内存
    
2.内存分段
    (1) 程序由多个逻辑分段组成，包括代码段、数据段、栈段、堆段，不同的段是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来。
    (2) 映射方式：虚拟地址 = 段号 + 段内偏移量，通过段号去段表找到段基地址，再由段内偏移量找到具体的位置。
  	(3) 不足
    	1) 内存碎片：外部 + 内部 // 有碎片所以要内存交换
    	2) 内存交换效率低：由于很容易产生外部碎片，不得不在磁盘swap区域把段移到磁盘上，再从磁盘读入内存到原先不同的位置，而磁盘速度慢，所以效率低下。
    	// 由此产生了分页式管理
3.内存分页
    // Linux中，每页是4KB，不会产生细小内存碎片，同时内存交换效率变高，但由于页表需要覆盖整个虚拟地址空间(也就是内存大小)，单级页表在4G空间就是4M，进程多的时候就会占用大量空间，所以需要多级页表；比如说二级页表，一级是1024个，二级是1024X1024，一级可以覆盖整个空间，只有用到的二级页表指向的物理地址再分配页表内存就行，不需像一级页表每个进程都是4M的分配；但同时由于页表级别多，访问内存次数多时间变大，所以在CPU中引入快表缓存页表项
    (1) 多级页表
    (2) 快表
    最常访问的几个页表项存储到访问速度快的硬件中，在CPU中加入专门存放程序最常访问的页表项的cache，叫快表(TLB)
    
4.页面置换算法
    // 缺页异常概述一下
    页表项：页号、物理页号、状态位(该页是否在内存中)、访问次数、修改位(该页是否被修改过)、硬盘地址
    // 缺页中断和普通中断的不同：缺页中断是在指令执行一半的时候就会切换到内核态，并且执行完中断处理程序后会重新执行该指令；而普通中断是指令执行完成的末尾切换
    缺页中断：如果在在页表中对应的页表项的状态位为无效，则CPU会发送缺页中断请求，中断处理函数会去磁盘找到该页，载入内存前需找到空闲页，并换入到内存，如果找不到就需要页面置换算法淘汰一个页面，如果页面是脏的，还需要刷到磁盘的物理页。
    (1) 先进先出置换算法
    (2) 最近最久未使用算法(LRU)：选择最⻓时间没有被访问的⻚⾯进⾏置换
    (3) 时钟页面置换算法
    (4) 最不常用算法(LFU):当发⽣缺⻚中断时，选择「访问次数」最少的那个⻚⾯，并将其淘汰
   
```



#### 4.1.3 进程

```java
1.进程代表一个程序的实例

2.进程的状态
	在⼀个进程的活动期间⾄少具备三种基本状态，即运⾏状态、就绪状态、阻塞状态、创建状态、结束状态，进入磁盘后还会分为阻塞挂起状态和就绪挂起状态
    
3.进程的结构(进程控制块 PCB)，将进程插入到就绪队列还是阻塞队列都是操纵PCB来完成
    (1) 进程描述信息：进程标识符、用户标识符(标识进程属于哪个用户)
    (2) 进程控制和管理信息：进程状态和优先级
    (3) 资源分配清单：页表、打开文件列表和IO设备信息
    (4) CPU 相关信息：CPU中各个寄存器的值
    
4.进程的上下文切换
    // 进程切换需要切换页表，还有清空CPU中缓存的快表
   进程由内核管理调度，所以进程切换只能发生在内核态
   CPU上下文：CPU寄存器和程序计数器
   上下文切换：上下文切换指的是内核（操作系统的核心）在CPU上对进程或者线程进行切换。包括用户空间的栈、全局变量等，内核空间的堆栈、寄存器等
   场景：
        1) 硬件中断
        2) 时间片完成
        3) sleep
        4) 优先级更高的进程
        
5.线程
   (1)线程就是进程中的一条执行流程，同一进程中的线程可以共享代码段、数据段、堆段、打开的文件等资源，但每个线程都有一套独立的寄存器和栈，所以在线程上下文切换时还是要保存私有的栈和寄存器中的变量。
   (2) 实现方式：
    	// PCB在内核中，操作系统可以看到，TCB在用户态的进程内，系统看不见
        1) 用户线程：由用户态的线程管理库管理，也就是在进程内部，内核访问不到，只能访问到该进程；进程中会维护TCB，TCB中记录了线程私有的栈、寄存器；用户线程切换无需切换到内核态
        缺点：Ⅰ一个用户线程阻塞会导致进程所包含的用户线程都不能执行，因为操作系统看不到线程，只能看到进程，线程阻塞相当于进程阻塞；Ⅱ用户线程运行后，除非主动交出使用权，否则其他用户线程无法打断当前运行线程，因为切换线程需要在内核态，操作系统才有。
        2) 内核线程
        3) 轻量级进程(LWP)：是内核支持的用户线程，一个进程可以有一个或多个LWP,一个LWP对应一个内核线程。简单理解，LWP代表的就是程序的执行线程，只不过可以由内核访问到。
    
6.线程与进程的比较
    不同：
    (1) 进程是资源分配的基本单位(内存、打开文件)，线程是CPU执行的基本单位
    (2) 线程能减少开销：
    	1) 切换方面：进程需要清空快表信息并切换页表，还有CPU硬件上下文，而线程只需要切换CPU硬件上下文。
    	2) 通信方面：进程通信需要通过内核，这就涉及到内核态的切换；而线程共享进程的内的资源数据，无需切换
    (3) 一个线程挂掉，对应的进程挂掉；一个进程挂掉，不会影响其他进程
    相同：
    (1) 同样具有就绪、阻塞、运行等状态
    
// 周转时间：进程运行和阻塞时间的和
// 等待时间：进程在就绪队列的时间
7.进程调度算法
    (1) 先来先服务算法(长作业运行时间长会导致后面的短作业等 太久)
    (2) 最短作业优先(长作业容易饿死)
    (3) 高响应比优先算法：等待时间 + 要求服务时间 / 要求服务时间 ，权衡了长作业和短作业
    (4) 时间片轮转算法
    (5) 最高优先级调度算法
    (6) 多级反馈队列调度算法 = 时间片轮转 + 最高优先级调度 (有多个排好序的优先级队列，每个队列按照先来先服务算法+时间片轮转算法，优先级越高时间片越小；反馈是说如果有新的进程加入到优先级高的队列就会转而去运行优先级高的队列) // 短作业在优先级高的队列就可以完成，长作业在优先级高的完成不了，转而去优先级低的队列获取的时间片增加也可以完成
        
8.进程间通信(IPC)
    // 关于线程间通信问题一般是说同一进程内的线程，而进程内的共享变量线程都可以看到，所以说进程无需考虑通信问题，一般是同步互斥问题
    进程的用户地址空间相互独立,所以一个进程访问不到另一个进程的地址空间,又因为进程共享内核空间，所以进程间通信需要借助内核。
    // 通信效率低，不适用频繁通信的场景
    (1) 管道：对应内核的一段缓冲区，以无格式的字节流传输数据
    	匿名管道(pipe)：不存在于文件系统中，只在内存中，进程关闭就没了；单向，如果需要双向就需要建立两个管道；只能在父子进程间通信
    	命名管道(FIFO)：存在于文件系统中，但是写的时候是向内存写，和普通文件有区别，进程关闭后会保存在文件系统中；半双工；任何进程间通信，只要可以访问到该管道名称。
    // 速度慢因为要切换内核态，不适合大数据传输，有限制
    (2) 消息队列
    	存在于内核中，采用链表-数据块的形式，效率比管道高一些，生命周期和内核一样，只要还没有被消费就会一直存在。
    // 进程互斥同步问题
    (3) 共享内存
		不同进程的虚拟地址经过页表会映射到相同的物理地址上，对于需要共享的数据所以一个进程修改数据，另一个进程也可以看到。
    // 解决进程互斥同步问题，34配合使用
    (4) 信号量 
    	信号量其实是⼀个整型的计数器，主要⽤于实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。
    	原理：主要包括P和V操作
    	P操作：信号量减1，如果小于零，进程需阻塞，否则正常运行
    	V操作：信号量加1，如果小于等于零，需要唤醒进程
    	初始化为1是互斥信号量，初始化为0是同步信号量;举例同步：比如现在A要先执行，B后执行，在执行A的代码后加V操作，执行B的代码前加P操作，就可以实现先A后B。
    (5) 信号
    	唯一的异步通信机制，可以在任意时刻发送信号给进程，包括硬件信号(ctrl+c)、软件信号(kill -数字 PID)，Linux提供了几十种信号，通过kill -l可以查看。当收到信号后可以选择执行系统 1)默认操作、2) 自定义函数处理、3) 忽略(有个别信号不可以忽略)。
    (6) socket
    	1) 网络通信：
    		tcp：服务端socket、bind(IP+port)、listen、accept(阻塞)；客户端socket、connect(三次握手)，然后服务端从全连接队列accept到socket，这个socket和监听的socket是两个socket。
    		udp：无需连接，服务端socket、bind，客户端socket、bind
    	2) 本地通信：bind时需要绑定一个本地文件，不用绑定IP地址和端口

8.互斥同步
    互斥：指同一时刻只能有一个线程访问资源
    同步：在某一事件上，需要有先后顺序(相互通知)

9.死锁
    // 四个必要条件：
    (1) 互斥条件：多个线程不能同时使⽤同⼀个资源
    (2) 占有并等待：线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1
    (3) 不可剥夺：在⾃⼰使⽤完之前不能被其他线程获取
    (4) 环路等待：线程获取资源的顺序构成了环形链
    // 避免死锁的方法，只要破坏其中一个条件就可以了。最常用的是使用资源有序分配法破坏环路等待条件：即不同线程在获取资源时顺序都一致，不会出现循环获取的条件。
```



#### 4.1.4 文件系统

```java
1.文件系统概述：
    文件系统为文件分配两个数据结构 = 索引节点（index node）+ ⽬录项
	索引节点在磁盘中，用来记录文件的元信息，如文件大小、权限、数据在磁盘的位置等
    目录项是内核维护的一个数据结构，不存在于磁盘，用来记录文件名索引节点指针和其他目录项的层级关系 // 目录项和目录不是一回事，目录是文件保存在磁盘中，用索引节点唯一标识，和普通文件不同的是，目录保存的是子目录或者普通文件，而普通文件保存的是文件数据；目录项是个数据结构在内核中，可以表示文件也可以表示目录
	文件系统操纵基本单位是数据块，为4KB，对应磁盘8个扇区(每个扇区512B)
2.磁盘
    (1) 超级块：块个数、块大小等
    (2) 索引节点区
    (3) 数据块区
   
3.层次结构
    由于文件系统很多，所以操作系统提供了一个统一的接口，引入了中间层-----虚拟文件系统
    应用程序 系统调用(write) -> 虚拟文件系统(sys_write()) -> 文件系统的写方法 -> buffer -> 磁盘
    
4.关于进程的文件
    每个进程会在PCB维护一个该进程的打开文件表，根据文件描述符可以找到打开文件表中的文件项信息，包括文件指针、文件打开计数器、磁盘位置等
    
5.文件存储方式：
    (1) 方式：
    	顺序存储
    	非连续
    		链表
    		索引(索引节点指向索引数据块)
    (2) Unix具体实现：
    	根据文件的大小变化：如果数据块小于10块，直接查找；超过10块，一级索引；不够用二级索引；再不够就三级索引
    
6.磁盘空闲区域管理方法：
    (1) 空闲表
    (2) 空闲链表
    (3) 位图:Linux中主要应用这种办法，每个位用01表示磁盘块是否空闲
    
7.软链接和硬链接的区别。
	软链接：一个目录项的inode指向的是另外一个文件的路径，也就是说两个目录项都可以访问相同的内容，但是inode不一样，所以访问软链接的时候相当于访问另外一个文件。可以在不同文件系统中对文件或者目录链接。
	硬链接：不同路径下的目录项中inode都指向同一个，这就是硬链接。只能在相同文件系统的已存在文件链接。

```



#### 4.1.5 输入输出设备

```JAVA
1.磁盘调度算法
    // 一般通过优化磁盘的访问请求顺序来优化磁盘性能
    (1) 先来先服务
    (2) 最短寻道时间优先
    (3) 扫描算法(双向)、循环扫描算法(单向) // 磁头移动到最末端
    (4) LOOK(双向)、C-LOOK(d向) // 磁头移动到最远请求即可
    
// 设备层并没有总结
```



#### 4.1.6 IO

##### 4.6.1.1 IO类型

- [阻塞式 I/O](https://www.pdai.tech/md/java/io/java-io-model.html#阻塞式-io)
- [非阻塞式 I/O](https://www.pdai.tech/md/java/io/java-io-model.html#非阻塞式-io)
- [I/O 复用](https://www.pdai.tech/md/java/io/java-io-model.html#io-复用)
- [信号驱动 I/O](https://www.pdai.tech/md/java/io/java-io-model.html#信号驱动-io)
- [异步 I/O](https://www.pdai.tech/md/java/io/java-io-model.html#异步-io)

##### 4.6.1.2 NIO

```java
// 普通IO流是基于单向字节流的，即一个流处理一个字节的数据；NIO是基于块的(channel+buffer实现)，channel全双工通信
1.通道 channel
    FileChannel: 从文件中读写数据； 
    DatagramChannel: 通过 UDP 读写网络中数据；
    SocketChannel: 通过 TCP 读写网络中数据；
    ServerSocketChannel: 可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个 SocketChannel。
2.缓冲区 buffer
        // Buffer是个抽象，对基本数据类型都做了封装继承自Buffer
    (1) 定义：发送给一个通道的所有数据都必须首先放到缓冲区中，同样地，从通道中读取的任何数据都要先读到缓冲区中。也就是说，不会直接对通道进行读写数据，而是要先经过缓冲区。
    (2) 参数：
        // 两个重要方法，flip()--切换成读模式，就是说limit = position，position = 0，读完后，执行clear()方法，可以将这些参数回归初始化。 读模式下不可以写，写模式可以读，但会有脏读问题。
         capacity: 最大容量；
		position: 当前已经读写的字节数；// 初始化为 0
		limit: 还可以读写的字节数。// 初始化后等于capacity
         
3.选择器 selector    
    除了FileChannel都可以注册到selector上
    与Selector一起使用时，Channel必须处于非阻塞模式下，否则将抛出异常IllegalBlockingModeException
    通道必须配置为非阻塞模式，否则使用选择器就没有任何意义了，因为如果通道在某个事件上被阻塞，那么服务器就不能响应其它事件，必须等待这个事件处理完毕才能去处理其它事件，显然这和选择器的作用背道而驰
    NIO 实现了 IO 多路复用中的 Reactor 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件。 
     // 通道注册到选择器上的事件    
     public static final int OP_READ = 1 << 0;
	public static final int OP_WRITE = 1 << 2;
	public static final int OP_CONNECT = 1 << 3;
	public static final int OP_ACCEPT = 1 << 4;
	// 监听事件，会一直阻塞直到有至少一个事件到达
	int num = selector.select();


// NIO在IO多路复用的具体体现
	NIO中三大关键是buffer、channel、selector，其中selector是实现IO多路复用的关键上层，底层代码调用何种多路复用需要适配操作系统的种类和版本，如select、poll、epoll(这三个是操作系统原生的IO多路复用，最终都会调用这三个)
// Reactor模式 (非阻塞同步)
    Reactor是高并发下的一种模式，Java中基于NIO可以实现Reactor
// NIO为啥是非阻塞的
    设置channel为非阻塞，如socketchannel、serversocketchannel,因为read和accept方法都是阻塞，那么在select()轮询时如果阻塞就无法响应其他客户端连接的事件，那么多路复用就会无意义。
```

##### 4.6.1.3 IO多路复用

```java
1.IO多路复用：
    (1) 意义：服务器在处理多个客户端连接时，最直接方式是为每一条连接创建一个线程，但是当连接达到上万时，这样不断创建销毁线程会会造成性能开销和资源浪费，所以采用线程池的方式进行资源复用；但是当某一连接占用的线程进行业务处理read()但没有读取到数据时，会发生阻塞，那么这个线程就无法处理其他连接，简单的方式是将read()改成非阻塞，然后不断轮询是否有数据，但当连接多的时候，会占用大量CPU的资源，效率也会变低。于是多路复用的技术产生，用一个系统调用监听我们关心的连接，会返回有事件的文件描述符(连接、读、写)，再去进行read、write业务处理。
    	但是IP多路复用是面向过程编程的，于是封装起来，称为Reactor模式，即I/O 多路复⽤监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程。Reactor是非阻塞同步的，即数据会准备到内核，然后应用进程通过read系统调用读取数据到用户区。
 		单 Reactor 单进程：redis
    	多 Reactor 多进程：nginx
    	多 Reactor 多线程：netty
    // 多路复用IO技术最适用的是“高并发”场景，所谓高并发是指1毫秒内至少同时有上千个连接请求准备好。其他情况下多路复用IO技术发挥不出来它的优势
    
    (2) 类型
    	1) select:  过程:客户端发送数据到网卡，网卡通过DMA拷贝到内核的网卡缓冲区，DMA发送中断信号给CPU，根据中断信号向量找到网卡的中断处理程序，该程序会将网卡缓冲区的内容依照端口号拷贝到内核中Socket结构的读缓冲区，并将该阻塞进程移入就绪队列，等待CPU执行。执行时，读取该进程的Socket文件描述符集合，并用bitmap表示，通过select()函数传入到内核中，内核会依照读缓冲区有数据的socket修改bitmap，并拷贝到用户态程序中，用户程序依照bitmap找到对应的socket文件进行数据的处理。（注：每次读数据需要两次bitmap的拷贝和遍历，并且下次还要重新置位bitmap，因为bitmap两次拷贝后发生变化了，比较浪费资源）
           // 问题：1.描述符的限制、2.每次调用 select 都需要从用户空间把描述符集合拷贝到内核空间，当描述符集合变大之后，用户空间和内核空间的内存拷贝会导致效率低下
    	2) poll: 基于链表存储，能解决socket文件描述符大小限制的问题，依然不能解决线性遍历以及用户空间和内核空间的低效数据拷贝问题
     	3) epoll: ①红黑树解决文件描述符限制问题和查找慢的问题，②把红黑树集合放入到内核中，避免全部拷贝，③使用双向链表缓存就绪的 socket，只需要拷贝这个双向链表到用户空间，再遍历就行
            
    (3) 工作模式:
		水平触发(默认)：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
         边缘触发：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。
         select和poll只有水平触发
    (4) 应用场景
         select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时要求更高的场景，比如核反应堆的控制。
         poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且epoll 的描述符存储在内核，不容易调试
         只需要运行在 Linux 平台上，并且有非常大量的描述符需要同时轮询，而且这些连接最好是长连接     

	5) reactor模式:
	
```

##### 4.6.1.4 零拷贝

![](https://raw.githubusercontent.com/Sadiyayan/review/master/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%96%B9%E5%BC%8F.png)

```java

// pagecache 还没总结
1.种类
在 Linux 中零拷贝技术主要有 3 个实现思路：用户态直接 I/O、减少数据拷贝次数以及写时复制技术
    (1) 用户态直接 I/O：应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，硬件上的数据直接拷贝至了用户空间，不经过内核空间。因此，直接 I/O 不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。
       用户态直接 I/O 只能适用于不需要内核缓冲区处理的应用程序，这些应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如数据库管理系统就是一个代表。其次，这种零拷贝机制会直接操作磁盘 I/O，由于 CPU 和磁盘 I/O 之间的执行时间差距，会造成大量资源的浪费，解决方案是配合异步 I/O 使用
	(2) 减少数据拷贝次数：在数据传输过程中，避免数据在用户空间缓冲区和系统内核空间缓冲区之间的CPU拷贝，以及数据在系统内核空间内的CPU拷贝，这也是当前主流零拷贝技术的实现思路。
    	1) mmap + write:mmap 主要的用处是提高 I/O 性能，特别是针对大文件。对于小文件，内存映射文件反而会导致碎片空间的浪费，因为内存映射总是要对齐页边界，最小单位是 4 KB，一个 5 KB 的文件将会映射占用 8 KB 内存，也就会浪费 3 KB 内存。
		  mmap 的拷贝虽然减少了 1 次拷贝，提升了效率，但也存在一些隐藏的问题。当 mmap 一个文件时，如果这个文件被另一个进程所截获，那么 write 系统调用会因为访问非法地址被 SIGBUS 信号终止，SIGBUS 默认会杀死进程并产生一个 coredump，服务器可能因此被终止。
    	2) sendfile:相比较于 mmap 内存映射的方式，sendfile 少了 2 次上下文切换，但是仍然有 1 次 CPU 拷贝操作。sendfile 存在的问题是用户程序不能对数据进行修改，而只是单纯地完成了一次数据传输过程
        3) sendfile + DMA gather copy:Linux 2.4 版本的内核对 sendfile 系统调用进行修改，为 DMA 拷贝引入了 gather 操作。它将内核空间（kernel space）的读缓冲区（read buffer）中对应的数据描述信息（内存地址、地址偏移量）记录到相应的网络缓冲区（ socket buffer）中，由 DMA 根据内存地址、地址偏移量将数据批量地从读缓冲区（read buffer）拷贝到网卡设备中，这样就省去了内核空间中仅剩的 1 次 CPU 拷贝操作。
           在硬件的支持下，sendfile 拷贝方式不再从内核缓冲区的数据拷贝到 socket 缓冲区，取而代之的仅仅是缓冲区文件描述符和数据长度的拷贝，根据这两个DMA可以在内存中找到数据并copy到DMA，并打包发送到网络上。

            
2. Java NIO零拷贝的实现
   (1) 在 Java NIO 中的通道（Channel）就相当于操作系统的内核空间（kernel space）的缓冲区，而缓冲区（Buffer）对应的相当于操作系统的用户空间（user space）中的用户缓冲区（user buffer）
        通道（Channel）是全双工的（双向传输），它既可能是读缓冲区（read buffer），也可能是网络缓冲区（socket buffer）。
	    缓冲区（Buffer）分为堆内存（HeapBuffer）和堆外内存（DirectBuffer），这是通过 malloc() 分配出来的用户态内存。
        堆外内存（DirectBuffer）在使用后需要应用程序手动回收，而堆内存（HeapBuffer）的数据在 GC 时可能会被自动回收。因此，在使用 HeapBuffer 读写数据时，为了避免缓冲区数据因为 GC 而丢失，NIO 会先把 HeapBuffer 内部的数据拷贝到一个临时的 DirectBuffer 中的本地内存（native memory），这个拷贝涉及到 sun.misc.Unsafe.copyMemory() 的调用，背后的实现原理与 memcpy() 类似。 最后，将临时生成的 DirectBuffer 内部的数据的内存地址传给 I/O 调用函数，这样就避免了再去访问 Java 对象处理 I/O 读写。
```

##### 4.6.1.5 网络包发送接收流程

```java
// 包括socket是如何起作用的？
```

##### 4.6.1.7 Linux常见命令

```java
ps -aux | grep PID，// 用来查看某PID进程状态
free -m // 命令查看内存使用情况
// owner/group/others
chmod 777(read、write、execute) 文件/目录
pwd // 命令用于显示工作目录    
```



### 4.2 计算机网络

#### 4.2.1 HTTP

```java
1.Http 超文本传输协议
    超文本指的是⽂字、图⽚、⾳频、视频等「超⽂本」数据
    传输指的是两点之间双向传输，协议就是共同遵守的规范
2.http状态码
    2xx：服务器成功处理了客户端请求
    	200：响应头有数据 204：响应头无数据
    3xx：发生重定向
    	302：临时重定向，请求资源在，但是需要用另一个url访问
    	304：缓存重定向，需要去本地缓存找 // http1.1缓存响应，但过期了就重新请求，但请求资源一样，就会有302
    4xx：客户端发送的报文有误，服务器无法处理
    	400：客户端请求报文有误，比较笼统的错误
    	403：服务器禁止访问资源，请求没有错
    	404：请求的资源在服务器没有找到
    5xx：客户端请求报文正确，服务器内部处理发生错误
    	500：服务器错误，笼统错误，和400一样
    	502(bad gateway)：服务器作为网关或者代理返回的错误码，自身正常，但后端服务器发生错误
    	503：服务器当前忙，暂时无法响应
3.get和post区别
    // http中安全指的是不会破坏服务器的资源，幂等指多次执行相同操作结果都是相同的
    get是从服务器获取资源(文本，页面，视频)，幂等且安全
    post向uri指定的资源提交数据，数据放在请求体中(和get的概念正好相反) 不幂等不安全
    
4.http的对比关系
    http/1.0短连接，即每发一次请求都要建立一次tcp连接，是串行发送的，即要等到下一次请求响应才可以继续发送下一个请求
  http/1.1长连接，支持管道传输，(长连接使得管道传输成为可能---可以并行发送请求，服务器按照顺序依次响应处理(需要排队),如果队头请求被阻塞，后续请求也无法处理)
    //总结
    1.1相对于1.0的改进和问题：
    	改进：TCP长连接、支持管道传输
    	问题：1) header未压缩，会发送重复的内容 2)管道传输会引起队头阻塞 3) 请求只能从客户端开始
   	2针对1.1不足的改进：
    	改进：建立在https的基础上
    	1) 压缩头，会去重：HPACK算法，客户端和服务器维护一个头信息表，针对字段生成索引号，以后只发索引号
    	2) 响应数据成为数据流，不再按照顺序响应，流中会标记有编号，解决了队头阻塞问题
    	3) 服务器会推送数据给客户端，比如js、css等静态资源
    	http2问题：多个http请求复用tcp连接，一旦发生丢包，触发TCP重传机制，就会阻塞所有的http请求
    3 还没有仔细研究 // 应用不广	
    // 1.1 和 2 的总结，两个问题都是基于tcp的问题
    	1.1中管道传输会引起队头阻塞
    	2 复用tcp连接，一旦丢包会阻塞所有的http请求
    
5.https
    在http和tcp中间加入了TLS安全协议，在tcp三次握手之后还需要TLS的握手
    // 功能：说白了就是解决三个问题：看到数据、加入数据、冒充
    信息加密：通过混合加密(对称加密和非对称加密)，握手阶段用公钥和私钥(非对称加密)，通信阶段只用私钥(对称加密) // 解决窃听的风险
    校验机制：保证数据不被篡改，通过摘要算法 // 解决篡改
    身份证书：将服务器公匙放入数字证书中，保证访问的网址是你想要访问的，而不是假的 // 解决冒充
    
    // TLS1.2需要四次握手的过程？？还没有看明白，
    // TLS1.3需要三次握手（http3用到）
    1) Client Hello
    
6.http1.1如何优化
    // 优化的并不是上述http1.1存在的问题，因为上述问题是http2解决的
    (1) 避免发送http请求 ----- 使用本地缓存，url为key，响应体为value
    (2) 减少http请求次数
    	1) 减少重定向的次数：针对代理服务器才可以这么做，正常具有代理服务器访问源服务器的话，产生重定向会有四次http请求，而第一次重定向在代理服务器完成而不用返回给客户端就可以 变为3次http，再有此客户端请求来时，代理服务器记住了直接"重定向",变为两次正常情况的两次http
    	2) 合并请求：把请求多个小文件的请求，变成一个请求，虽然请求资源一样，但减少了重复发送的请求头；另外在一个tcp下，http1.1多请求的情况可能会有队头阻塞，所以会建立不同的tcp连接，如果合并请求，也会减少tcp数量，减少了建立tcp的时间
    (3) 减少http响应数据大小
    	无损压缩：文本、源代码
    	有损压缩：图片、视频、音频
    
```

#### 4.2.2 TCP

##### 4.2.2.1 三次握手与四次挥手 

```java
TCP是⾯向连接的、可靠的、基于字节流的传输控制协议

// 连接！！！
⽤于保证可靠性和流量控制所维护的某些状态信息的组合，包括Socket、序列号和窗⼝⼤⼩称为连接。// 三次握手后才可以初始化Socket、序列号和窗⼝⼤⼩来保证TCP连接说可靠的
    
MTU是网络传输最大报文包，MSS是网络传输数据最大值。
MSS就是你需要发出去的数据大小，MSS加包头数据就等于MTU 。
MSS就是TCP数据包每次能够传输的最大数据分段
    
TCP头部的控制位
    ACK：该位为1，表示确认应答号有效，除了刚开始建立连接的SYN包之外必须置为1
    RST：该位为1时，表示TCP出现异常需要强制断开连接
    SYN：该位为1时，希望建立连接，并且将序列号字段随机设定初始值
    FIN：该位为1时，希望断开连接。通信结束希望断开连接时，通信双方主机就可以互换FIN为1的TCP段。
 
// 连接过程中确认应答号更新到哪里？    
三次握手的原因，也就是说为什么不是三次握手或者四次握手
    两次握手：1) 无法防止历史连接的建立 2) 会造成双方资源的浪费 3) 无法同步双方序列号
    四次握手：三次握手就已经可以保证可靠连接，所以不需要更多的通信次数
    
既然IP层会分片，TCP层为什么也要分片
    如果TCP层不分片，数据只有一个TCP的头部，在IP层分片后如果某一段丢失了，发送方就不会收到接收方的ACK，所以发送方的TCP就认为整个TCP数据全丢了，超时后，就会导致发送方的整个IP层都重传，所以为了提高传输效率，就需要在TCP层分片，丢包后，只需要重传对应的TCP分片即可。
    
// 什么是SYN攻击，如何解决
    
    
四次挥手
    1) 客户端 FIN // FIN的意思只代表不能发送数据，还可以接受数据
    2) 服务端 ACK
    3) 服务端 FIN
    4) 客户端 ACK
    为什么是四次：服务端在ACK后可能还需要处理并发送数据，所以不能一次发送ACK和FIN，所以需要四次挥手
  
// 主动关闭连接的才有TIME_WAIT状态
// 为什么TIME_WAIT状态是2MSL
    保证旧连接的正确关闭
// 为什么需要TIME_WAIT状态
    防止旧连接的数据包
    保证旧连接的正确关闭
// TIME_WAIT过大怎么办
    客户端：TIME_WAIT过多会占用端口，影响创建新的连接
    服务端：服务器只用一个端口监听连接，把对应连接交给处理线程，不会影响端口，当TIME_WAIT过多只会影响系统资源。
```

##### 4.2.2.2 TCP机制

```java
可靠性传输的问题：数据的破坏、丢包、重复、顺序错乱等问题
// 重传机制可以解决丢包和数据重复的问题
// 方式一：序列号+确认应答(能解决顺序c乱)
    (1) 超时重传：超过RTO的数据包没有收到ACK就会重传，两种情况：数据包丢了或者接收端发送的ACK丢了
    	问题：超时周期比较长
    (2) 快速重传：当收到三个相同的ACK报文时，会在定时器过期之前(注意这里是定时器过期之前，也就是解决了超时重传的问题)，重传丢失的报文段
    	问题：不知道之前已经发送的报文段哪些到了哪些没到
    // 当ACK小于SACK的序列号时，表示是SACK，数据包有丢失
    (3) SACK：在TCP头部种加一个SACK的东西，用于接收端发送ACK时告诉发送端本次收到了哪些数据
     // 当ACK大于SACK的序列号时，表示是D-SACK，数据包有重复发送，具体原因发送方可知
    (4) D-SACK：可以让发送方知道，是数据包丢了还是ACK包丢了，还是数据包被网络延迟了
    
// 滑动窗口机制
    分为发送窗口和接收窗口(因为有时延的原因，所以是约等)
    发送窗口大小由接收窗口确定
    
// 流量控制机制
    TCP通过让接收方指明从发送方接收的数据大小来进行流量控制，避免发送方的数据填满接收方的缓存
    
// 拥塞控制机制
    在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤。
    目的是避免让发送方的数据填满整个网络。
    只要发生超时重传机制网路就会认为出现了拥塞。
    算法：
    	(1) 慢启动：当发送⽅每收到⼀个 ACK，拥塞窗⼝ cwnd 的⼤⼩就会加 1。
    	(2) 拥塞避免：到达慢启动门限时，每当收到⼀个 ACK 时，cwnd 增加 1/cwnd
    	(3)
    	(4)
```



## 5.Spring体系

### 5.1 Spring

```java
spring事务的传播行为
```



### 5.2 SpringMVC

```java
1.组件执行流程
	1)前端控制器根据请求地址由处理器映射器找到具体的处理器，再返回给前端控制器。
	2)前端控制器通过处理器适配器调用具体的处理器并返回modelandview(也可只有view，即逻辑视图)
	3)前端控制器将ModelAndView传给视图解析器，将逻辑视图拼接前后缀转化为具体的物理视图（对拼接	好的物理视图转发），生成view对象返回给前端控制器
    //注：
    	Ⅰ：逻辑视图本质也是转发，如果指定转发或者重定向的关键字，路径必须完整，而且不再走视图			解析器了
    	Ⅱ：model的本质是向一个request域中存放数据，重定向会使其失效
	4)前端控制器将模型数据填充至view中，并响应给用户
	
2.常用注解
	@RequestMapping() // 添加到方法和类上，也就是处理器映射器找的东西
		value：用于指定请求的URL。它和path属性的作用是一样的
		method：用来限定请求的方式
		params：用来限定请求参数的条件
		
	// 以下三个注解都是用于方法中的形参上，第一个最常用
	@RequestParam // 解决请求的参数name名称与Controller的方法参数名称不一致问题
		defaultValue 设置参数默认值
		name 匹配页面传递参数的名称
		required 设置是否必须传递参数，默认值为true；如果设置了默认值，值自动改为false
	@RequestHeader // 获取请求头的数据
	@CookieValue // 获取某一cookie中的数据。
    
    @SessionAttributes //向request域存入的key为value时，同步到session域中，作用在类上
   
    @RequestBody  
    	该注解用于Controller的方法的形参声明，当使用ajax提交并指定contentType为json串形式时，通过				HttpMessageConverter接口转换为对应的POJO对象。// 作用于形参
    @ResponseBody
    	该注解用于将Controller的方法返回的对象或集合，通过HttpMessageConverter接口转换为json串，如果是		String字符串则直接返回，不再走视图解析器。//作用于方法上
    
    // Restful风格
    @PathVariable :用来接收RESTful风格请求地址中占位符的值
    @RestController = @Controller + @Responsebody
        
3.异常处理机制
    实现HandlerExceptionResolver接口
    @ExceptionHandler注解作用于方法上
```

### 5.3SpringBoot

```java
1.功能：起步依赖、自动配置
    //Spring Boot 是所有基于 Spring 开发的项目的起点
    //配置文件加载顺序：yml>yaml>properties,也就是说properties的配置文件会覆盖前两种文件的相同属性值
    起步依赖实现原理：任何springboot项目都会继承父项目spring-boot-starter-parent，该项目会继承父项目spring-boot-dependencies，在该项目中，会在<properties>标签中定义依赖版本属性值，在<dependencyManagement>标签中定义好了在自己源项目中引入了依赖的坐标的版本号，所以源项目只需要依赖的坐标，不需要指定版本号即可引入所有起步依赖。
    
2.注解：
    1)由配置文件属性注入过程理解：
    	实体类加上@Component生成对象放入到IOC容器中，依照以下两个注解的内容从配置文件中赋予对象变量的值
    @ConfigurationProperties(prefix = "person")
    // 将配置文件中以person开头的属性值通过setXX()方法注入到实体类对应属性中，实体类需要加上@Component生成对		象放入IOC容器中
    @Value("${person.id}")
    // 直接将配置文件中的person.id的值对注解下的变量进行注入，无需走setXX()方法
    
    2)自定义配置
    @PropertySource("classpath:test.properties") // 加载自定义配置文件
    @Configuration // 表明是一个配置类，SpringBoot会自动扫描，替代了传统的xml文件
    
    3)@SpringBootApplication下的注解
   
 3.springboot不支持jsp的原因：
    在Jetty和Tomcat容器中，Spring Boot应用被打包成war文件可以支持JSP。但Spring Boot默认使用嵌入式Servlet容器以JAR包方式进行项目打包部署，这种JAR包方式不支持JSP。
```

### 5.4 SpringCloud

```java
// 可以通过连接数据库来生成实体类，右键选择scripted extension 
// @Table(name="xxx") 该注解将实体类映射到数据库表，name指定了表的名称可以和实体类名字不一样，除此之外我的理解是该实体有了此注解后可以融合mybatisplus，mapper层继承basemapper的泛型指定了实体，相当于指定了表，方便开发，但目前没看过源码，无从考究。
1.微服务与SOA的不同：
    SOA同样是拆分服务，分布式项目，但粒度比微服务大，同时对服务的治理功能没有微服务的功能多
    
2.SpringCloud和Dubbo的对比：
    协议：SpringCloud实现由feign组件采取http协议进行微服务调用，dubbo基于RPC默认采用TCP，效率更高一些
    功能：SpringCloud的功能组件很全，一站式，以SpringBoot为基石，即依赖管理和自动配置的优势方便开发，而Dubbo		的功能提供并不全，例如服务注册与发现需要zookeeper完成。
    
3.核心概念
    Spring Cloud其实是一套规范，具体实现有SCN和SCA
    (1) 服务注册与服务发现：zookeeper(CP)、eureka(AP，集群无主从之分)、nacos(AP和CP切换)
    	   服务注册中心可以支持服务数量动态伸缩，服务提供者和注册中心维持心跳机制，某一服务宕机了，可以剔除。
    	原理：消费者和服务提供者都向注册中心注册，消费者先拉取提供者列表，再去调用提供者，实现了解耦，方便动		  态伸缩服务提供者，除此之外注册中心还提供服务检测机制，将宕机的服务剔除并通知对应的消费者。消费者定期		拉取服务列表并实现负载均衡和熔断的实现。
    		
    (2) 负载均衡
    	服务熔断和服务降级：熔断是降级的一种策略 而降级是对于整体的负荷的考虑,资源不够用了就暂停非重要资源的		    访问。 降级又分为主动降级和被动降级,主动降级:大促时主动关闭非核心业务;被动降级:熔断降级、限流降级等 		 熔断在一段时间内服务失败率达到阈值触发熔断,触发熔断后的一段时间内客户端将直接返回熔断干预的返回结果,		并且会尝试熔断恢复。
        流控是对外部来的大流量进行控制，熔断降级(熔断一般针对下游服务的响应时间)的视角是对内部问题进行处理！！
    (3) 链路追踪
    API网关
        
4.SCN组件
      1) eureka
        //心跳检测:
		30s微服务会向注册中心续约一次，注册中心90s没收到续约就会剔除该微服务（这里两个参数都是在客户端置），		服务端默认是60s检查一次，如果发现距离上次续约的时间已经过了90s，那么就会剔除该服务
        //客户端缓存：
        消费者会在本地缓存从注册中心拉取的服务提供者（IP:port），即使eureka全部宕机，仍可以访问服务提供者。默		认30S拉取服务最新的注册表并缓存到本地
        //元数据：
        分为标准元数据和自定义元数据，都存在server instance中
        //自我保护机制
        自我保护模式是一种针对网络异常波动的安全保护措施，使用自我保护模式能使Eureka集群更加的健壮、稳定的		运行，就是说健康或者不健康的微服务都会保存，这种情况下发生在5分钟内超过85%的客户端节点都没有正常的心	   跳，此时就会触发自我保护机制，这时的eureka服务器可以接受来自客户端的请求（前提是可以接受到），但内部的		元数据不同同步到其他集群节点。主要目的就是说可能是server自身的网络有问题，而不是微服务有问题，怕“误	   杀”。当重新收到心跳数恢复阀值以上时，该EurekaServer节点就会自动的退出自我保护模式。和zookeeper相比，	   只有一半以上节点存活，集群才可用，否则处于瘫痪状态。
      2) ribbon
         //负载均衡分类：
            客户端和服务端，服务端包括nginx，也就是客户端直接访问nginx的地址，由nginx做负载均衡，路由到目标地址；客户端包括ribbon，就是由客户端直接从一堆地址在均衡的基础上选择一个进行访问。
         //负载均衡策略（主要记三种，其实有很多种）：
            RoundRobinRule：轮询策略，如果超过十次没获取到则为空
            ZoneAvoidanceRule：区域权衡策略（默认策略），先过滤再轮询，过滤掉超时、连接多、和不符合zone要求		     的节点
            BestAvailableRule：最小连接数策略，遍历serverList，选取出可用的且连接数最小的一个server
         // 简单原理：
            就是在restemplate里面加了一个拦截器，然后在拦截器里面加了负载均衡算法，实现客户端的负载均衡
         // 用法：
            在生成restemplate对象的方法上添加一个注解@LoadBalanced
      3) Hystrix
         // 舱壁模式：
            所有加@HystrixCommand注解的方法，当有请求到来时，都会进入到hystrix维护的一个默认为10的线程池			   中，很有可能线程池满了，请求进不去直接调用失败，但服务提供者是可用的情况，所以需要在
            @HystrixCommand属性中设置threadPoolKey，代表开启了舱壁模式（实现线程隔离），一个threadPoolKey			  代表一个线程池。
         // 工作流程：
            当出现调用错误时，开一个默认10s的时间窗，如果达到最小连接请求数，并且达到错误的阈值，则服务提供者			 进入熔断状态，此时进入自我修复机制，会默认开启一个5s的活动窗口，在此期间，hystrix会放行一个到达的			 请求，如果可以连接上服务提供者，则取消熔断状态。
            这里一共四个参数：时间窗、最小连接数、错误阈值、活动窗口
      4) Feign
         // 组成：
            以接口注解的方式调用http请求，Feign = RestTemplate + Ribbon + Hystrix
            启动类使用注解@EnableFeignClients，feign的依赖包中包括了Ribbon + Hystrix的依赖
            @FeignClient(name=相同的名字就会出现报错, fallback=xxx.class),所以最好将调用一个微服务的信息		      定义在一个Feign接口中。
         // 对ribbon的支持
            Feign已经ribbon的依赖和自动配置，默认ribbon就是打开状态
            Feign默认的请求处理超时时长1s，如果配置Ribbon的超时，则会以Ribbon的为准，就是说Feign超时时间就			   是Ribbon的超时时间
         // 对Hystrix的支持
            默认Hystrix不开启，需要开始Feign对Hystrix的支持
            熔断也有超时时间，调用服务提供者是否超时是按照Feign/Hystrix中设置的超时时间小的来算
      5) GateWay(引入的是web-flux模块而不是Springmvc)// Spring Cloud官方的组件
         // 组成
            主要包括路由和过滤器，路由属性包括断言、服务id、服务uri和条件过滤，其中uri支持动态路由，即			   ip+host不能写死，格式：lb://微服务名称
		   过滤器是找到路由后和对应微服务之间的一层，分为pre和post，分别对应调用前过滤和响应过滤。类型分为全			  局过滤器和单个路由过滤器。
            “pre”类型过滤器中可以做参数校验、权限校验、流量监控、日志输出、协议转换等，在“post”类型的过滤器			中可以做响应内容、响应头的修改、日志的输出、流量监控
         // 流程
           客户端向Spring Cloud GateWay发出请求，然后在GateWay Handler Mapping中找到与请求相匹配的路由，			  将其发送到GateWay Web Handler；Handler再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻			 辑，然后返回（分为pre和post）。
      6) Config（自动刷新需要用到Spring Cloud Bus）
           分布式配置管理方案，分为客户端、服务端
           //流程：
               在github一个项目中配置一个对应的文件，server端可以直接访问到（即使文件变化，也可以再次拉取				  到，因为二者直接通信），client端配置server的信息，既可以拉取到对应的配置信息，需要将配置文件			    名由application.yml -> bootstrap.yml，bootstrap.yml启动项目时会加载配置server的数据并缓存			    到本地，但在server端的文件改变后，客户端得到的依然是缓存中的数据。解决方法如下刷新策略：
           //刷新策略：
               手动刷新：client端使用 post+refresh，从server端(而不是client端本地缓存)获取最新数据
               自动刷新：思路就是一次通知，处处生效，访问server端 post+bus refresh
               		过程：在server和client间加入消息总线spring cloud bus，当server端使用post+bus 							refresh后，会发送消息给bus，bus会触发消息队列（rabbitmq/kafka），此时队列会把消						 息发送给binding的微服务，告诉他们使用post+refresh去server端拉取最新的配置信息，						 实现了一次通知处处生效
5.SCA组件
     1) Nacos = eureka + config + bus
     2) Sentinel = Hystrix + 更多功能
             
```

### 5.5 ShardingJDBC

```java
1.分库分表
    1) 原因：单机存储容量遇到瓶颈；连接数,处理能力达到上限。
    2) 分类：// 分库分表的意思是分成库或者分成表
    	垂直分库：根据表的业务不同，将一个库中的表分到各个服务器的数据库中，一定程度上可以解决并发性能
    	水平分库：将一张表的数据分到不同的数据库中，一定程度上可以解决并发性能，如果分库后的库还很大，接着考				  虑水平分表
    	垂直分表：将一张表的数据按照字段分成多张表
    	水平分表：将一张表的数据分到同一个数据库中的多张表里
    	// 总结：水平分可以解决单机存储容量问题，分库可以解决并发问题
    	// 首先应该考虑的是索引和缓存，如果数据量持续上涨再考虑分库还是分表
    
2.主从复制:
	通过搭建主从架构, 将数据库拆分为主库和从库，主库负责处理事务性的增删改操作，从库负责处理查询操作，能够有效	  的避免由数据更新导致的行锁
3.分库分表的问题：
    事务一致性问题
    跨节点关联的问题（关联查询）
    分页排序查询的问题
    主键避重问题
    公共表的问题
4.ShardingJDBC
    轻量级Java框架，在Java的JDBC层提供额外的服务
    使用shardingJDBC前需要提前对数据库分库分表，应用程序通过引入的shardingJDBC依赖操作分库分表后的数据库和表
    相比mycat，它是一个中间件应用，实现了mysql的协议，代理了mysql
5.ShardingJDBC的使用
    流程(针对配置文件)：指定数据源的信息(哪台主机、哪台数据库) -> 指定数据节点(数据源的哪张表，也就是指定逻辑					 表的具体信息) -> 分片策略(指定分片键和算法) -> [指定分布式ID生成算法(雪花算法)]
    1) 水平分库和水平分表流程：本质上是一张表先进行水平分库，然后因为单机的数据库的数据量太大，才会导致继续水平分表。分库需要指定多个数据源信息（只是水平分表一个数据源就ok，因为只在一个数据库上），数据节点就是所有的实际表信息（都映射为一张逻辑表，和本质里的一张表相对应），最后针对逻辑表指定分库分表的路由策略
    2) 垂直分库的流程：几个库就指定几个数据源，由于是垂直分库，有很多的逻辑表，所以数据节点信息需配置多个，分片规则根据具体是否分来配置
    3) 读写分离流程：主库从库分别配置数据源信息，指定逻辑库，即哪个是主库哪个是从库，可以理解由逻辑库整合，由逻辑库指定逻辑表的信息（配置数据节点）
    4) 操作公共表
```

### 5.6 Mybatis

```java
1.Mybatis的基本原理   
    (1)
    // 该步骤只是加载了配置文件的输入流，包括核心配置文件和xxxmapper.xml
    InputStream is = Resources.getResourceAsStream("SqlMapConfig.xml");
    (2)
    // 生成SqlSessionFactory工厂对象
    // 使用dom4j对上述配置文件解析，xxxmapper中的每一项都会被封装成一个MappedStatement对象(包括sql、形参类型、返回参数)，总体封装成一个map集合，key为xxxmapper.id,如usermapper.findAll
    SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(is);
    (3)
    // 生成SqlSession会话对象
    //如果设置为true则执行增删改都会持久化，相当于直接提交事务，不设置需要在最后commit
    SqlSession sqlSession = sqlSessionFactory.openSession([true]);
    (4)
    // sqlSession并不会操作数据库底层是委派给Executor执行器执行JDBC的操作，sql等参数由对应的MappedStatement对象获取MappedStatement对象由"UserMapper.delete"从步骤(2)map集合中获取
    // SqlSession十分强大,包括selectOne、selectList、insert、update、delete、commit、rollback方法
    sqlSession.delete("UserMapper.delete", 50);

    // DML语句，手动提交事务
    sqlSession.commit();
    // 释放资源
    sqlSession.close();

2.Mybatis代理开发的原理
    sqlMapConfig.xml中配置<package name="org.mybatis.builder"/>是为了加载和xxxmapper接口同名包的xxxmapper.xml文件，此时配置<mapper resource="org/mybatis/builder/userMapper.xml"/>即直接引入xxxmapper.xml的方式也可以，但是不能做到简化，需要一个一个引入。
    
    @MapperScan作用：
    	生成代理对象存入IOC容器中(关于Spring项目中什么时候加载xxxmapper.xml文件没有弄清楚，目前个人理解应该是在配置生成mapper代理对象的路径时，根据代理开发会扫描同样路径下的xxxmapper.xml文件，如果有则由sqlSessionFactory加载生成mappedstatement存入map集合)
    
    InputStream is = Resources.getResourceAsStream("SqlMapConfig.xml");
    SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(is);
    SqlSession sqlSession = sqlSessionFactory.openSession([true]);

    // 基于JDK动态代理生成UserMapper的代理对象
    UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
    // 代理对象执行接口方法时会调用InvacationHandler中重写的invoke方法，底层还是调用了
    // sqlSession.selectOne(xxxMapper.id,paramter)等相应的方法，再调用执行器执行JDBC操作
    List<User> list = userMapper.findAll();

3.常用属性
    (1) useGeneratedKeys // 将自增生成的主键映射到实体属性keyProperty中
    <insert id="save" parameterType="user" useGeneratedKeys="true" keyProperty="id">
        INSERT INTO `user`(username,birthday,sex,address)
        values(#{username},#{birthday},#{sex},#{address})
    </insert>
```



### 5.7 Mybatis Plus

```java
1. 针对实体类的注解(类或者字段加对应的注解)
    @TableName("xxx") //mp根据继承basemapper泛型的类来找到数据源中库里的表名，如果表名不一致，需要加上该注解
    @TablePrefix("tb_") // 表示映射数据库中以"tb_"开头+实体类名字的表名
    @TableId(type = IdType.AUTO) //指定id类型为自增，mq在该注解中定义了一些主键生成策略
    // 对象中的属性名和字段名不⼀致的问题（⾮驼峰）,本质就是把表中的字段名as 成实体类的字段名
    @TableField(value = "表中字段名") 
    // 表中没有实体类字段名称
    @TableField(exist = false)
    // 不查询实体类的某一字段
    @TableField(select = false)
 
2.mp sql自动注入的原理
    // 自定义的方法并没有实验如何注入，等自己写项目的时候debug一下？
    // 猜测自定义的方法和mybatis的实现原理一样
    ISqlInjector负责SQL的注⼊⼯作，它是⼀个接⼝，AbstractSqlInjector是它的实现类
    在AbstractSqlInjector的inspectInject()方法中会循环注入basemapper中的方法，以xxxmapper.方法名为key，mapperstatement对象为value注入map集合中，此后代理对象调用basemapper接口中的方法时，就会触发动态代理的机制，调用InvacationHandler中重写的invoke方法，该方法会去map集合中根据key找到value，再找到对应的sql，由sqlsession原始方法执行

3.常用配置信息
    // 加载核心配置文件
	mybatis-plus.config-location = classpath:mybatis-config.xml
    // 加载mapper对应的xml文件
    //classpath* 除了加载本工程下的文件，还会加载本工程所有依赖下classpath对应的文件
    mybatis-plus.mapper-locations = classpath*:mybatis/*.xml
```

## 6.项目

### 6.1 微服务教育项目

<img src="https://raw.githubusercontent.com/Sadiyayan/review/master/%E9%A1%B9%E7%9B%AE/SSO%E6%B5%81%E7%A8%8B.png" style="zoom:67%;" />

```java
// 遇到的问题
	eureka客户端的依赖和web依赖需要各自引入，不要引入父工程
    数据库的依赖单独引入，如果引入父工程，会在eureka中需要datasource
    停掉某一端口的方法:
		netstat -ano | findstr 7001 //查找pid
         taskkill /F /PID xxx // 根据pid杀死进程
    linux的防火墙要关掉 System stop firewalld
    redis如果是slave只读，需要slaveof no one变成master，才能写
1.eureka注册中心 //7001
2.广告微服务 // 8001
    设置广告位（promotion_ad）,轮播组件有图片的url，点击图片会跳转link（图片和跳转在前端div属性设置的）
    侧边广告位：纯前端代码
            
3.网关微服务// 9001
    给广告微服务加了网关 // 为啥要加？？
            
4.用户模块
       (1)SSO(single sign on)单点登录：
         问题：不同tomcat服务器的session肯定不一样，如果是个微服务项目，想要登录的话，登录一次只会保存在一个服务器的session域中，如果访问了集群项目，其他服务器无法获得之前服务器的session，还是需要重新登录，很麻烦，所以不能用session解决 // 本质就是不同服务器的session不共享。需要一个中间件解决
         解决：SSO可以在一个浏览器中登录一次，访问其他地址时刷新就可以实现自动登录
            
         1) 内容：
            Json Web Token，基于json格式信息一种token令牌。
		   JWT token 包含三部分，第一部分header、第二部分payload、第三部分签证  
         	// 这里具体都包含什么需要仔细研究一下
        	// 所谓的SSO认证中心就是自己搭建的一个模块，可以是集群，不影响
            
         2) 逻辑：
		    后端验证登录成功会创建token(包括用户的信息)，并设置过期时间保存在redis中，
        	前端第一次登录得到token后保存在cookie中，刷新页面(或者打开新的页面)后会从浏览器加载该cookie对应的token，再去redis中验证token是否正确，前端根据返回的值判断，如果是后端设置登录成功的响应值，就会显示用户信息，并重新设置该cookie的存活时间；登出账户后，需要删除cookie，并设置不显示用户信息
        	如何解决不同服务器项目登录问题：传统登录后用户信息保存在服务器的session中，如果后端是集群项目，那么登录一次后用户信息只能保存在一个服务器中，无法解决多次登录在不同服务器的问题；而SSO被单独抽出来替代了传统的登录功能，采取token的方式(用户信息保存在token中)以cookie保存在浏览器中，再次访问时会拿着保存的cookie去SSO中保存在redis的token进行解析验证，然后返回，剩下的逻辑在前端中完成。// 本质上SSO模块替代了用户登录功能在不同session域的问题，而SSO部署集群的信息是可以共享的，所以不存在用户登录模块集群的问题。
          3) 问题：
            cookie跨域问题:由于域名不同，用户向系统A登录后，系统A返回给浏览器的Cookie，用户再请求系统B的时候不会将系统A的Cookie带过去。// 解决：在写到客户端的时候设置Cookie的domain。让多个域名共享Cookie
            
```

### 6.2 基础秒杀

#### 6.2.1 问题

```java
1.配置mybatis-generator-maven-plugin要放在和pluginManagement同级别下，而不能放在pluginManagement下的plugins里面，否则会爆红
2.&useSSL=false   mybatis-generator插件的url要添加
3.数据库连接的配置一定不能写错
    
    
4.@CrossOrigin(allowCredentials = "true",allowedHeaders = "*")
// 单体的问题
    如何发现容量问题
    如何水平扩展
    查询效率的低下
    活动开始前页面被疯狂刷新
    库存行锁的问题
    下单操作多缓慢
    浪涌流如何解决
```

跨域感知session

跨域感知session需要解决两个问题，第一个是解决跨域问题，第二个是解决跨域cookie传输问题

#### 跨域问题

解决跨域问题有很多种方式，可以参考本章最后的扩展资料跨域问题的解决方式，我们在一开始的课程视频中使用了springboot自带的crossOrigin注解，如下（注意，和目前的课程中不完全一致，如何演进的继续往下看）

```
@CrossOrigin(origins = {"*"},allowedHeaders = "*")
```

这个注解一加后，所有的http response头上都会加上
Access-Control-Allow-Origin * 以及
Access-Control-Allow-Headers * 两个头部，这样可以满足CORS的跨域定义，我们的ajax看到这两个头部就认定对应的域名接收任何来自或不来自于本域的请求

#### 跨域传递cookie的问题

跨域和跨域传递cookie是两个不同纬度的问题，我们依靠上述的方式解决了跨域的问题，但是要做到跨域感知session需要解决在跨域的前提下将cookie也能传上去，这个时候就需要设置另外一个头部 ，我们的cross origin演变为

```
@CrossOrigin(origins = {"*"},allowCredentials = "true",allowedHeaders = "*")
```

使用了allowCredentials后Access-Control-Allow-Credentials头被设置成true，同时前端设置xhrField:{withCredential:true}后，浏览器在ajax请求内带上对应的cookie头部和后端的allowCredentials配合在一起解决跨域传递cookie的问题。由于课程中仅仅使用了get和post的方法，而这两个方法在跨域请求中都是可以用的，因此allowedHeaders可以不加。

另外当设置了allowCredentials = “true"的时候origins = {”*"}就失效了，因为一旦设置了跨域传递cookie就不能再设置接受任何origins了，而springboot的实现方式是返回的allow origin取request内的origin即我们自己对应的html页面的路径。这样就可以做到在哪个origin上使用跨域就允许哪个origin，一样能达到我们想要的效果。

ps：许多浏览器包括safari和最新版本的chrome默认设置都是不支持携带跨域cookie的，即便我们代码写成允许，浏览器底层也做了限制，因此在调试的时候我们可以关闭对应的限制，也可以使用扩展阅读内的其他跨域处理方式

#### 6.2.2 模块

##### 6.2.2.1 用户模块

```java
// 用户信息和用户密码要分成两个表，(因为密码要加密，实际在企业级单独维护)
    
2.service需要返回带有密码的VO对象，所以需要封装一个，而controller层不需要带有密码的对象，其他不需要的字段也可以删掉，所以也自己封装一个VO对象
 
// 响应：封装含有Object数据和响应码的实体，返回给前端，摒弃了http状态码和错误页的方式
3.异常机制在项目中很重要，比如找不到用户信息，需要抛出异常，项目中controller是最后一道关口，可以在此处理，利用springmvc的@ExceptionHandler注解完成对抛出异常的处理
    
4.用户注册

5.用户登录
```

##### 6.2.2.2 商品模块

```java
// 无需考虑太多，注意就是stock表和item表要分开，以便后续分库分表的操作
1.mysql中价格的字段设置成了double
    而在service层的itemModel中价格的类型是BigDecimal，是因为Java中double字段在传到前端时会有精度损失
    
2.controller中主要有三个逻辑
    新建商品信息
    展示某一商品的信息
    	在获取某一商品的信息时，会查询该itemmodel的promomodel字段，也就是看是否有活动，并在promomodel中根据当前时间比较并设置status信息，来判断活动状态，在controller层如果promomodel不为null，就会在itemVO中设置相关属性，并显示在前端上
    展示所有商品信息
```

##### 6.2.2.3 交易模块

秒杀只有等到活动开始后才可以下单

```java
// 订单表只有一张，但会涉及到用户表、商品表、库存表
1.新建订单 -- 三个参数(用户id，商品id，商品数量) // 加上事务
    (1) 校验参数
    	下单的商品是否存在，用户是否合法，购买数量是否正确
    (2) 订单减库存 / 支付减库存
    (3) 订单入库
    	需要注意的是，订单表的主键id是订单号，不是自增的，定义为：
    		订单有16位，前8位为时间信息，年月日，中间6位为自增序列(如果订单量多可以扩展)，最后两位为分库分表位,暂时不考虑
    		// 设置生成订单号的方法需要加上事务的传播行为：
    		// @Transactional(propagation = Propagation.REQUIRES_NEW)
    		目的：不管该方法是否在事务中，都会开启一个新的事务，不管外部事务是否成功。最终都会提交掉该事务，为了保证订单号的唯一性，防止下单失败后订单号的回滚
```

##### 6.2.2.4 秒杀活动模块

```java
// 有一个promo(营销)表 对应的Date日期字段尽量把不要用java.util中的，而是用joda-time依赖下的

将商品模块和活动模块整合！！
```

### 6.3 优化秒杀

#### 6.3.1 总结基础秒杀

```
分层设计：MVC+领域模型(业务层) 结合了多张表的字段，比如用户信息的话，密码和其他信息是分成两个表的，但在领域模型中会结合用户用到的所有字段，满足业务逻辑。(需要在DO之前设计),至于为什么用户信息分成两个表，是因为除了登录和修改密码等操作，展示操作是最为频繁的，而且不需要用到密码，分成两个表，对应基础信息的表可以减少表的大小

关于表：(1) 至于为什么用户信息分成两个表，是因为除了登录和修改密码等操作，展示操作是最为频繁的，而且不需要用到密码，分成两个表，对应基础信息的表可以减少表的大小;

（2）商品表 分为基础信息和库存表，分开的原因是在对库存修改时，需要加上行锁操作，如果都在一起的话，会导致查询商品信息时无法查询，影响效率；同时把库存表分开可以方便后期做分库分表

（3）订单表的主键不是自增的，是自己设计的
```

6.2.2 笔记

```java
1.跨域的设置问题没懂？
2.异常处理  AOP切面？
```



# 一些不错的博客/Github 推荐

- SnailClimb 的 Github ：[https://github.com/Snailclimb](https://github.com/Snailclimb "https://github.com/Snailclimb") 。（自荐一波哈！主要专注在 Java 基础和进阶、Spring、Spring Boot、Java 面试这方面。）
- 徐靖峰个人博客 ：[https://www.cnkirito.moe/](https://www.cnkirito.moe/ "https://www.cnkirito.moe/")（探讨 Java 生态的知识点，内容覆盖分布式服务治理、微服务、性能调优、各类源码分析）
- 田小波：[http://www.tianxiaobo.com/](http://www.tianxiaobo.com/ "http://www.tianxiaobo.com/") （Java 、Spring 、MyBatis 、Dubbo）
- 周立的博客： [http://www.itmuch.com/](http://www.itmuch.com/ "http://www.itmuch.com/")（Spring Cloud、Docker、Kubernetes，及其相关生态的技术）
- Hollis: [https://www.hollischuang.com/](https://www.hollischuang.com/ "https://www.hollischuang.com/") (Java 后端)
- 方志朋的专栏 ： [https://www.fangzhipeng.com/](https://www.fangzhipeng.com/ "https://www.fangzhipeng.com/") （Java 面试 Java 并发 openresty kubernetes Docker 故事 )
- 纯洁的微笑 : [http://www.ityouknow.com/](http://www.ityouknow.com/ "http://www.ityouknow.com/") （Java、SpringBoot、Spring Cloud）
- 芋道源码： [http://www.iocoder.cn/](http://www.iocoder.cn/ "http://www.iocoder.cn/") (专注源码)。

